{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Face Mask Dataset with InceptionV3 on CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate image data generators for training, validation and test data\n",
    "\n",
    "![Load Data](assets/Training_1-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ingest the data for training purposes we utilize the Keras **ImageDataGenerator** class.  This allows us to easily read in a directory that is structured with each category in its respective folder.  Earlier in the training during the Exploration phase we structured the data in this manner along with specific folders for train, test and validation.  We're going to utilize a generator for each of those folder classes.\n",
    "\n",
    "At this point we also are planning to use **Inception V3** which has a Height and Width requirement of **299x299** so we instantiate that here so we can utilize it throughout the rest of the notebook.  The generator will also resize images to that size before feeding it into training, testing or validation so we make sure it will work successfully.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activity \n",
    "\n",
    "In the cell below, change the **WIDTH** and **HEIGHT** values to match the size requirement for the Inception V3 topology **299x299**.  We're also going to utilize the same batch size for all three sets of data.  Set the **BATCH_SIZE** to **64** then click **Run**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ukrida\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\ukrida\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\ukrida\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\ukrida\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\ukrida\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\ukrida\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\ukrida\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\ukrida\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\ukrida\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\ukrida\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\ukrida\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\ukrida\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Data Set\n",
      "Found 3130 images belonging to 2 classes.\n",
      "\n",
      "Validation Data Set\n",
      "Found 446 images belonging to 2 classes.\n",
      "\n",
      "Test Data Set\n",
      "Found 897 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input, decode_predictions\n",
    "\n",
    "WIDTH=299\n",
    "HEIGHT=299\n",
    "BATCH_SIZE=64\n",
    "test_dir = '../dataset/test/'\n",
    "train_dir = '../dataset/train/'\n",
    "val_dir = '../dataset/val/'\n",
    "\n",
    "#Train DataSet Generator with Augmentation\n",
    "print(\"\\nTraining Data Set\")\n",
    "train_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "train_flow = train_generator.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(HEIGHT, WIDTH),\n",
    "    batch_size = BATCH_SIZE\n",
    ")\n",
    "\n",
    "#Validation DataSet Generator with Augmentation\n",
    "print(\"\\nValidation Data Set\")\n",
    "val_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "val_flow = val_generator.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(HEIGHT, WIDTH),\n",
    "    batch_size = BATCH_SIZE\n",
    ")\n",
    "\n",
    "#Test DataSet Generator with Augmentation\n",
    "print(\"\\nTest Data Set\")\n",
    "test_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_flow = test_generator.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(HEIGHT, WIDTH),\n",
    "    batch_size = BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizations for CPU\n",
    "\n",
    "![CPU Optimization](assets/Training_1-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CPUs, which includes Intel® Xeon processors, achieve optimal performance when TensorFlow is built from source with all of the instructions supported by the target CPU.\n",
    "\n",
    "Beyond using the latest instruction sets, Intel has added support for the Intel® Math Kernel Library for Deep Neural Networks (Intel® MKL-DNN) to TensorFlow. While the name is not completely accurate, these optimizations are often simply referred to as MKL or TensorFlow with MKL. TensorFlow with Intel MKL-DNN contains details on the Intel® MKL optimizations.\n",
    "\n",
    "The two configurations listed below are used to optimize CPU performance by adjusting the thread pools.\n",
    "\n",
    "- __intra_op_parallelism_threads__: Nodes that can use multiple threads to parallelize their execution will schedule the individual pieces into this pool.\n",
    "- __inter_op_parallelism_threads__: All ready nodes are scheduled in this pool.\n",
    "\n",
    "These configurations are set via the tf.ConfigProto and passed to tf.Session in the config attribute as shown in the snippet below. For both configuration options, if they are unset or set to zero, will default to the number of logical CPU cores. Testing has shown that the default is effective for systems ranging from one CPU with 4 cores to multiple CPUs with 70+ combined logical cores. A common alternative optimization is to set the number of threads in both pools equal to the number of physical cores rather than logical cores.\n",
    "Intel MKL uses the following environment variables to tune performance:\n",
    "- __KMP_BLOCKTIME__ - Sets the time, in milliseconds, that a thread should wait, after completing the execution of a parallel region, before sleeping.\n",
    "- __KMP_AFFINITY__ - Enables the runtime library to bind threads to physical processing units.\n",
    "- __KMP_SETTINGS__ - Enables (true) or disables (false) the printing of OpenMP* runtime library environment variables during program execution.\n",
    "- __OMP_NUM_THREADS__ - Specifies the number of threads to use.\n",
    "\n",
    "See Optimizing for CPU, \n",
    "https://www.tensorflow.org/performance/performance_guide#optimizing_for_cpu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activity\n",
    "In the cell below, update **NUM_PARALLEL_EXEC_UNITS** to __8__, **KMP_BLOCKTIME** to **\"1\"**, and then click **Run**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, CSVLogger\n",
    "from tensorflow.keras import optimizers, models\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import os\n",
    "\n",
    "NUM_PARALLEL_EXEC_UNITS = 8\n",
    "\n",
    "#Set Performance Parameters for MKL and Tensorflow using Keras backend\n",
    "#TensorFlow\n",
    "config = tf.ConfigProto(\n",
    "    intra_op_parallelism_threads=NUM_PARALLEL_EXEC_UNITS,\n",
    "    inter_op_parallelism_threads=1\n",
    ")\n",
    "\n",
    "session = tf.Session(config=config)\n",
    "K.set_session(session)\n",
    "\n",
    "#MKL and OpenMP\n",
    "os.environ[\"OMP_NUM_THREADS\"] = str(NUM_PARALLEL_EXEC_UNITS)\n",
    "os.environ[\"KMP_BLOCKTIME\"] = \"1\"\n",
    "os.environ[\"KMP_SETTINGS\"] = \"1\"\n",
    "os.environ[\"KMP_AFFINITY\"]= \"granularity=fine,verbose,compact,1,0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Hyperparamaters - Recommendations\n",
    "\n",
    "![Hyperparameters](assets/Training_1-3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What batch size?\n",
    "A batch size is the subset of the training dataset that is utilized in one iteration.\n",
    "It has been observed in practice that when using a larger batch there is a significant degradation in the quality of the model, as measured by its ability to generalize. \n",
    "The lack of generalization ability is due to the fact that large-batch methods tend to converge to sharp minimizers of the training function.\n",
    "\n",
    "In general, batch size of 32 is a good starting point, and you should also try with 64, 128, and 256.\n",
    "Batch size below 32 might get too slow because of significantly lower computational speed as a result of not exploiting vectorization to the full extent.\n",
    "\n",
    "https://arxiv.org/abs/1609.04836\n",
    "\n",
    "#### What Learning rate to use? :\n",
    "The __Learning Rate__ is the size of the steps we take to reach a (local) minimum.\n",
    "A lower learning rate means more steps and therefore trains for a longer time while higher learning rate means less steps which therefore trains for shorter time.\n",
    "Also, too low a learning rate never progresses, and too high a learning rate causes instability and never converges. In between, there is a band of “just right” learning rates that successfully train.\n",
    "\n",
    "There is no single learning rate that works for all optimizers.\n",
    "Learning rate can affect training time by an order of magnitude.\n",
    "Learning rate performance did not depend on model size. The same rates that performed best for 1x size performed best for 10x size.\n",
    "\n",
    "#### Why and what optimizer to use?\n",
    "Gradient Descent is one of the most popular algorithms to perform optimization and by far the\n",
    "most common way to optimize neural networks. __Stochastic Gradient Descent(SGD)__ is a variant of Gradient Descent in which only a few of the samples (selected by batch_size) are used to compute gradient in every iteration. SGD can be optimized with parameter __'Momentum'__ which is a method that helps accelerate SGD in the relevant direction and dampens\n",
    "oscillations.\n",
    "\n",
    "One of the challenges of __SGD__ is that the same learning rate applies to all parameter updates. \n",
    "If the dataset is sparse and the features have very different frequencies, it will not be necessary to update all of them to the same extent, but rather a larger update for rarely occurring features. This problem is addressed by __Adaptive Learning-Rate optimizers__ (Adagrad, Adadelta, RMSprop and Adam) that adapt the learning\n",
    "rate to the parameters, performing larger updates for infrequent and smaller updates for frequent\n",
    "parameters.\n",
    "\n",
    "The main down side of the __Adaptive Learning Rate optimizers__ is that they require more computation to be performed for each parameter in each training step and more state to be retained for each parameter.\n",
    "While a simple __SGD__ Optimizer could equally be used with less computational requirements, it would require more hyperparameter tuning (__learning rate__) before it would converge as quickly.\n",
    "\n",
    "In all, most of the optimizers manage to converge in a reasonable time.\n",
    "\n",
    "https://arxiv.org/pdf/1609.04747.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Transfer Learning?\n",
    "\n",
    "Transfer learning is taking the weights from a previously trained network and use them as the basis for the weights in a new network.  Since there is a difference in number of categories between data sets we normally remove the top layers of the network and re-instantiate them to match the number of categories we're trying to choose between.  Using Transfer Learning will significantly speed up your training process by utilizing things like edge detection that the previous training has already learned then you can fine tune the network to your data set.\n",
    "\n",
    "A commonly used transfer learning base is the ImageNet data set weights.\n",
    "\n",
    "\"What is ImageNet?\n",
    "ImageNet is an image dataset organized according to the WordNet hierarchy. Each meaningful concept in WordNet, possibly described by multiple words or word phrases, is called a \"synonym set\" or \"synset\". There are more than 100,000 synsets in WordNet, majority of them are nouns (80,000+). In ImageNet, we aim to provide on average 1000 images to illustrate each synset. Images of each concept are quality-controlled and human-annotated. In its completion, we hope ImageNet will offer tens of millions of cleanly sorted images for most of the concepts in the WordNet hierarchy.\"\n",
    "\n",
    "http://image-net.org/about-overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Training Top Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by brining in the pre-defined **InceptionV3** network provided by Keras.  We'll make sure to include the ImageNet weights since we want to utilize those weights for Transfer Learning which will speed up our training significantly.  We'll also make sure the **Top Layers** aren't included since we don't want to predict 1001 classes and will then modify the network to fit our dataset.\n",
    "\n",
    "Take the base model and add a GlobalAveragePooling2D layer and pass it the output of the base model.  We'll then add a final **Dense Layer** or **Fully Connected Layer** that has a **softmax activation** which will do our predictions on the number of classes in our dataset.  To make sure this is verstile we use the train_flow generator class indicies number so that it will automatically use the correct number of classes in the dataset.\n",
    "\n",
    "Now we iterate over the initial layers of the base model and disable them for training by changing the layer.trainable variable to False.  This means we'll only train over the new layers that we added specifically for our dataset.\n",
    "\n",
    "Then compile your model and add the optimizer that you want to use.  In this case we'll be using **Adam** with a **Learning Rate** of **0.001**.  We also want to use **loss** of **Categorical Crossentropy** since we have a multi-class classification problem.\n",
    "\n",
    "We can print out the summary of the network after compiling so that we can verify the total number of nodes needing to be training and that the last layers were correctly added to the network.\n",
    "\n",
    "![Compile Model](assets/Training_1-4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activity\n",
    "In the cell below, update **lr** to **0.001**, and then click **Run**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ukrida\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\ukrida\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 149, 149, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 149, 149, 32) 96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 149, 149, 32) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 147, 147, 32) 9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 147, 147, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 147, 147, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 147, 147, 64) 18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 147, 147, 64) 192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 147, 147, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 73, 73, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 73, 73, 80)   5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 73, 73, 80)   240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 73, 73, 80)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 71, 71, 192)  138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 71, 71, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 71, 71, 192)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 35, 35, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 35, 35, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 35, 35, 48)   9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 35, 35, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 35, 35, 48)   144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 35, 35, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 35, 35, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 35, 35, 96)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 35, 35, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 35, 35, 64)   76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 35, 35, 96)   82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 35, 35, 32)   6144        average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 35, 35, 64)   192         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 35, 35, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 35, 35, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 35, 35, 32)   96          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 35, 35, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 35, 35, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 35, 35, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 35, 35, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 35, 35, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 35, 35, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 35, 35, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 35, 35, 96)   55296       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 35, 35, 48)   144         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 35, 35, 96)   288         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 35, 35, 48)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 35, 35, 96)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 35, 35, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 35, 35, 64)   76800       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 35, 35, 96)   82944       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 35, 35, 64)   16384       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 35, 35, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 35, 35, 64)   192         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 35, 35, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 35, 35, 64)   192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 35, 35, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 35, 35, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 35, 35, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 35, 35, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 35, 35, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 35, 35, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 35, 35, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 35, 35, 96)   55296       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 35, 35, 48)   144         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 35, 35, 96)   288         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 35, 35, 48)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 35, 35, 96)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 35, 35, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 35, 35, 64)   76800       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 35, 35, 96)   82944       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 35, 35, 64)   18432       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 35, 35, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 35, 35, 64)   192         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 35, 35, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 35, 35, 64)   192         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 35, 35, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 35, 35, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 35, 35, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 35, 35, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 35, 35, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 35, 35, 64)   192         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 35, 35, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 35, 35, 96)   55296       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 35, 35, 96)   288         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 35, 35, 96)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 17, 17, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 17, 17, 96)   82944       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 17, 17, 384)  1152        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 17, 17, 96)   288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 17, 17, 384)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 17, 17, 96)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 17, 17, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 17, 17, 128)  384         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 17, 17, 128)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 17, 17, 128)  114688      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 17, 17, 128)  384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 17, 17, 128)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 17, 17, 128)  114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 17, 17, 128)  384         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 17, 17, 128)  384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 17, 17, 128)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 17, 17, 128)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 17, 17, 128)  114688      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 17, 17, 128)  114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 17, 17, 128)  384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 17, 17, 128)  384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 17, 17, 128)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 17, 17, 128)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 17, 17, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 17, 17, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 17, 17, 192)  172032      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 17, 17, 192)  172032      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 17, 17, 192)  576         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 17, 17, 192)  576         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 17, 17, 192)  576         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 17, 17, 192)  576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 17, 17, 192)  0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 17, 17, 192)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 17, 17, 192)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 17, 17, 192)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_30[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 17, 17, 160)  480         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 17, 17, 160)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 17, 17, 160)  179200      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 17, 17, 160)  480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 17, 17, 160)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 17, 17, 160)  179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 17, 17, 160)  480         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 17, 17, 160)  480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 17, 17, 160)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 17, 17, 160)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 17, 17, 160)  179200      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 17, 17, 160)  179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 17, 17, 160)  480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 17, 17, 160)  480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 17, 17, 160)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 17, 17, 160)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 17, 17, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 17, 17, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 17, 17, 192)  215040      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 17, 17, 192)  215040      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 17, 17, 192)  576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 17, 17, 192)  576         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 17, 17, 192)  576         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 17, 17, 192)  576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 17, 17, 192)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 17, 17, 192)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 17, 17, 192)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 17, 17, 192)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 17, 17, 768)  0           activation_40[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 17, 17, 160)  480         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 17, 17, 160)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 17, 17, 160)  179200      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 17, 17, 160)  480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 17, 17, 160)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 17, 17, 160)  179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 17, 17, 160)  480         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 17, 17, 160)  480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 17, 17, 160)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 17, 17, 160)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 17, 17, 160)  179200      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 17, 17, 160)  179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 17, 17, 160)  480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 17, 17, 160)  480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 17, 17, 160)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 17, 17, 160)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 17, 17, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 17, 17, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 17, 17, 192)  215040      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 17, 17, 192)  215040      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 17, 17, 192)  576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 17, 17, 192)  576         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 17, 17, 192)  576         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 17, 17, 192)  576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 17, 17, 192)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 17, 17, 192)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 17, 17, 192)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 17, 17, 192)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 17, 17, 768)  0           activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "                                                                 activation_58[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 17, 17, 192)  576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 17, 17, 192)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 17, 17, 192)  258048      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 17, 17, 192)  576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 17, 17, 192)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 17, 17, 192)  258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 17, 17, 192)  576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 17, 17, 192)  576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 17, 17, 192)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 17, 17, 192)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 17, 17, 192)  258048      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 17, 17, 192)  258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 17, 17, 192)  576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 17, 17, 192)  576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 17, 17, 192)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 17, 17, 192)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 17, 17, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 17, 17, 192)  258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 17, 17, 192)  258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 17, 17, 192)  576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 17, 17, 192)  576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 17, 17, 192)  576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 17, 17, 192)  576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 17, 17, 192)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 17, 17, 192)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 17, 17, 192)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 17, 17, 192)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 17, 17, 768)  0           activation_60[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 17, 17, 192)  576         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 17, 17, 192)  0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 17, 17, 192)  258048      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 17, 17, 192)  576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 17, 17, 192)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 17, 17, 192)  258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 17, 17, 192)  576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 17, 17, 192)  576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 17, 17, 192)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 17, 17, 192)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 8, 8, 320)    552960      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 8, 8, 192)    331776      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 8, 8, 320)    960         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 8, 8, 192)    576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 8, 8, 320)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 8, 8, 192)    0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 8, 8, 1280)   0           activation_71[0][0]              \n",
      "                                                                 activation_75[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 8, 8, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 8, 8, 448)    1344        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 8, 8, 448)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 8, 8, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 8, 8, 384)    1548288     activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 8, 8, 384)    1152        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 8, 8, 384)    1152        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 8, 8, 384)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 8, 8, 384)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 8, 8, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 8, 8, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 8, 8, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 8, 8, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 8, 8, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 8, 8, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 8, 8, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 8, 8, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 8, 8, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 8, 8, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 8, 8, 192)    245760      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 8, 8, 320)    960         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 8, 8, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 8, 8, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 8, 8, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 8, 8, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 8, 8, 192)    576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 8, 8, 320)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 8, 8, 768)    0           activation_78[0][0]              \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 8, 8, 768)    0           activation_82[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 8, 8, 192)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 8, 8, 2048)   0           activation_76[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 8, 8, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 8, 8, 448)    1344        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 8, 8, 448)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 8, 8, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 8, 8, 384)    1548288     activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 8, 8, 384)    1152        conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 8, 8, 384)    1152        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 8, 8, 384)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 8, 8, 384)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 8, 8, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 8, 8, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 8, 8, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 8, 8, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 8, 8, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 8, 8, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 8, 8, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 8, 8, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 8, 8, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 8, 8, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 8, 8, 192)    393216      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 8, 8, 320)    960         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 8, 8, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 8, 8, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 8, 8, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 8, 8, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 8, 8, 192)    576         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 8, 8, 320)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 8, 8, 768)    0           activation_87[0][0]              \n",
      "                                                                 activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 8, 8, 768)    0           activation_91[0][0]              \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 8, 8, 192)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 8, 8, 2048)   0           activation_85[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1024)         2098176     global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            2050        dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 23,903,010\n",
      "Trainable params: 2,100,226\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initialize InceptionV3 with transfer learning\n",
    "base_model = applications.InceptionV3(weights='imagenet', \n",
    "                                include_top=False, \n",
    "                                input_shape=(WIDTH, HEIGHT,3))\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# and a dense layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(len(train_flow.class_indices), activation='sigmoid')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer=optimizers.Adam(lr=0.001), metrics=['accuracy', 'binary_accuracy'], loss='binary_crossentropy')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Training / Training Callbacks\n",
    "\n",
    "![Callback and Training](assets/Training_1-5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start our training we're going to utilize the Keras Fit Generator method.  This will allow us to pass in the ImageDataGenerator/flow_from_directory structure from above directly to the method.  Here is where we can also set our epochs, validation set, and callbacks.\n",
    "\n",
    "Setting an epoch count can really depend on the dataset that you're using and how long you're willing to wait for the training to complete.  During out testing phase we ended up trying 100 epoch's and utilizing Callbacks to make sure that we're not overfitting.\n",
    "\n",
    "It's useful to have a **validation set** that you can try to maximize toward when doing your training.  This way you have an idea of how well things are going on a small subset of data that isn't the test set.  If you use the test set for this purpose it will be harder to tell if you're generalizing well or if you're only fitting to the test set specifically and won't do well in a real world test.  Earlier in the notebook we insantiated a validation set generator which we can pass in here by setting the generator to the validation_data paramter.\n",
    "\n",
    "We need to specify both the validation and training number of steps per epoch.  We can use variables defined in our generators so that we're not hard coding numbers directly in these fields.  This is done by taking our sample size and dividing by our batch size then utilizing the math.ceil function so we properly account for the final smaller batch in the dataset.\n",
    "\n",
    "Lastly, we define 4 different callbacks that we're going to use during our training.  Callbacks are called after an epoch of training is complete and then will perform whatever action is necessary.\n",
    "\n",
    "### Callbacks\n",
    "\n",
    "**ModelCheckpoint**: Used to save our checkpoint based on a certain set of criteria.  In this case we're monitor our loss and looking for the min value.  After an epoch it will check to see if the loss is lower than the previous epoch of training and if so then to save the model to disk.  We're also indicating that we want to save only the best model so the previous model will be overwritten.  This will minimize the amount of disk space taken up by models.\n",
    "\n",
    "**TensorBoard**: Utilizing this checkpoint will write out the tf.events file during training so we can view them in TensorBoard.  We need to indicate a location for the logs to be saved and the update frequence for which we want the data.  In our case we're asking for batch frequence data so we need to also pass in the batch size to the function.  We can then start Tensorboard and point the --logdir parameter at the directory where the logs are saved to see how our training is going.\n",
    "\n",
    "**EarlyStopping**: This is used to make sure that we're not overtraining and overutilizing our compute.  It will monitor a metric after every epoch and see how much it has changed since the previous epoch.  If it hasn't changed significantly over the last n number of epochs it will end the training prematurely since there isn't much gain from going further.  In this case we're monitoring loss and asking for it to minimize the value, we also give a patience value of 5 which means the value has to not change significantly for 5 epochs before the training will be stopped.\n",
    "\n",
    "**CSVLogger**: Another logging technique that can be easier to read by directly inspecting the log file.  This can be useful if you're not interested in using TensorBoard or just want to use a simpler logging output.  It will write out the metrics we're keeping track of during training and append them to the CSV file giving during the instanitation of the callback.\n",
    "\n",
    "### Activity\n",
    "\n",
    "In the cell below, update **epochs** to __5__ , and then click **Run**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "48/49 [============================>.] - ETA: 18s - loss: 0.2851 - acc: 0.8875 - binary_accuracy: 0.8875\n",
      "Epoch 00001: loss improved from inf to 0.28271, saving model to top_layers.iv3.hdf5\n",
      "49/49 [==============================] - 961s 20s/step - loss: 0.2828 - acc: 0.8879 - binary_accuracy: 0.8879 - val_loss: 0.1602 - val_acc: 0.9327 - val_binary_accuracy: 0.9327\n",
      "Epoch 2/5\n",
      "48/49 [============================>.] - ETA: 17s - loss: 0.0901 - acc: 0.9633 - binary_accuracy: 0.9633\n",
      "Epoch 00002: loss improved from 0.28271 to 0.08929, saving model to top_layers.iv3.hdf5\n",
      "49/49 [==============================] - 936s 19s/step - loss: 0.0891 - acc: 0.9637 - binary_accuracy: 0.9637 - val_loss: 0.2089 - val_acc: 0.9159 - val_binary_accuracy: 0.9159\n",
      "Epoch 3/5\n",
      "48/49 [============================>.] - ETA: 18s - loss: 0.0403 - acc: 0.9852 - binary_accuracy: 0.9852\n",
      "Epoch 00003: loss improved from 0.08929 to 0.04046, saving model to top_layers.iv3.hdf5\n",
      "49/49 [==============================] - 942s 19s/step - loss: 0.0404 - acc: 0.9851 - binary_accuracy: 0.9851 - val_loss: 0.1377 - val_acc: 0.9484 - val_binary_accuracy: 0.9484\n",
      "Epoch 4/5\n",
      "48/49 [============================>.] - ETA: 18s - loss: 0.0619 - acc: 0.9786 - binary_accuracy: 0.9786\n",
      "Epoch 00004: loss did not improve from 0.04046\n",
      "49/49 [==============================] - 937s 19s/step - loss: 0.0612 - acc: 0.9789 - binary_accuracy: 0.9789 - val_loss: 0.0922 - val_acc: 0.9585 - val_binary_accuracy: 0.9585\n",
      "Epoch 5/5\n",
      "48/49 [============================>.] - ETA: 18s - loss: 0.0523 - acc: 0.9780 - binary_accuracy: 0.9780\n",
      "Epoch 00005: loss did not improve from 0.04046\n",
      "49/49 [==============================] - 940s 19s/step - loss: 0.0586 - acc: 0.9762 - binary_accuracy: 0.9762 - val_loss: 0.1466 - val_acc: 0.9406 - val_binary_accuracy: 0.9406\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "top_layers_file_path=\"top_layers.iv3.hdf5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(top_layers_file_path, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "tb = TensorBoard(log_dir='logs', batch_size=val_flow.batch_size, write_graph=True, update_freq='batch')\n",
    "early = EarlyStopping(monitor=\"loss\", mode=\"min\", patience=5)\n",
    "csv_logger = CSVLogger('logs\\iv3n-log.csv', append=True)\n",
    "\n",
    "history = model.fit_generator(train_flow, \n",
    "                              epochs=5, \n",
    "                              verbose=1,\n",
    "                              validation_data=val_flow,\n",
    "                              validation_steps=math.ceil(val_flow.samples/val_flow.batch_size),\n",
    "                              steps_per_epoch=math.ceil(train_flow.samples/train_flow.batch_size),\n",
    "                              callbacks=[checkpoint, early, tb, csv_logger])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model\n",
    "\n",
    "![Evaluate Model](assets/Training_1-6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate our training results we can use the **evaluation generator**.  This will integrate well with our data generator from the previous step that points to our testing set.  We will again have to specify the amount of steps used by calculating with samples and batch size and indicated earlier.\n",
    "\n",
    "We're also going to receive three different results from our evaluate generator: **loss**, **accuracy** and **top k accuracy**.  These are given since when we compiled our model we indicated that we're evaluting for **categorical crossentropy** for **loss** and our **metrics** were **accuracy** and **top_k_categorical_accuracy** which will evaluate if our result was in the top 5 confidence.  If we added or removed a metric during compiliation it would be reflected here in our evaluation generator and we would get more or less values in return from this function.\n",
    "\n",
    "### Activity\n",
    "\n",
    "Click the cell below and then click **Run**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 102s 7s/step - loss: 0.3336 - acc: 0.8802 - binary_accuracy: 0.8802\n",
      "Loss:  0.3335878928502401\n",
      "Acc:  0.8801561\n",
      "Top 5:  0.8801561\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(top_layers_file_path)\n",
    "loss, acc, top_5 = model.evaluate_generator(\n",
    "    test_flow,\n",
    "    verbose = True,\n",
    "    steps=math.ceil(test_flow.samples/test_flow.batch_size))\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Acc: \", acc)\n",
    "print(\"Top 5: \", top_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write Labels File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Deep learning, when we're training our network we're using a numerical value for the actual class that is predicated at the end of each batch through the network.  The network itself doesn't care what the actual string class name is, only that it's optimizing for one of the n classes you have in your dataset.  \n",
    "\n",
    "So when we move forward and use our network we need to indicate what numerical value the network was using to represent the correct class name.  We can do this by iterating over any of the data generator class_indicies values and use a list comprehension to extract the values.  We're going to write these values out in order to a text file to represent the numerical value mapping to class name for future use.\n",
    "\n",
    "### Activity\n",
    "\n",
    "Click the cell below and then click **Run**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = [k for k,v in train_flow.class_indices.items()]\n",
    "with open('iv3-labels.txt', 'w+') as file:\n",
    "    file.write(\"\\n\".join(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model with Sample image\n",
    "\n",
    "![Test Model](assets/Training_1-7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we're done training we want to see the results for our model on a test image.  We're going to load a random image chosen from our test set and run it through the model.\n",
    "\n",
    "We can use Keras to load the image and resize it to the given size required for the network.  We then need to convert the Image object to an array and add an extra axis to the array so it's in the format (n, h, w, c).  Then it will be run through the preprocessing step required for all inputs into the network and passed into the model.predict run for the results.\n",
    "\n",
    "After running the image through the model for a prediction we need to map the indicies to the correct class names and we can also take a look at the confidence values returned by the softmax.  \n",
    "\n",
    "To do this we'll start by sorting the prediction results by index.  Then we can get the top X number of values from the end of the array and then we'll reorder the array in the reverse order since the highest confidence is the last value in the array.  We can then use this array to read the confidence and label of the top X results.\n",
    "\n",
    "### Activity\n",
    "\n",
    "Click the cell below and then click **Run**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Category:  without_mask\n",
      "Raw Predictions:  [[0.14231904 0.7480055 ]]\n",
      "\n",
      "Top 3 confidence: 0.7480055 0.14231904\n",
      "Top 3 labels: without_mask with_mask\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import glob\n",
    "import random\n",
    "\n",
    "file_list = glob.glob(\"../Dataset/test/*/*\")\n",
    "img_path = random.choice(file_list)\n",
    "img_cat = os.path.split(os.path.dirname(img_path))[1]\n",
    "print(\"Image Category: \", img_cat)\n",
    "img = image.load_img(img_path, target_size=(299, 299))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "preds = model.predict(x)\n",
    "print(\"Raw Predictions: \", preds)\n",
    "\n",
    "top_x = 3\n",
    "top_args = preds[0].argsort()[-top_x:][::-1]\n",
    "preds_label = [label[p] for p in top_args]\n",
    "print(\"\\nTop \" + str(top_x) + \" confidence: \" + \" \".join(map(str, sorted(preds[0])[-top_x:][::-1])))\n",
    "print(\"Top \" + str(top_x) + \" labels: \" + \" \".join(map(str, preds_label)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform Keras Model to Tensorflow Frozen Graph\n",
    "\n",
    "![Freeze Graph](assets/Training_1-8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras utilizes the h5 or hdf5 file format when saving its model.  If we want to use our model outside of Keras, in **OpenVINO**, we need a frozen pb file to pass in when using a Tensorflow model.  We can do that directly from Keras by utilizing the below functions.\n",
    "\n",
    "First we need to make sure that you set the learning phase to 0 or you might end up not correctly getting the output node from the session.  Then we grab the session and output names and pass them to graph_util.convert_variables_to_constants.\n",
    "\n",
    "\"If you have a trained graph containing Variable ops, it can be convenient to convert them all to Const ops holding the same values. This makes it possible to describe the network fully with a single GraphDef file, and allows the removal of a lot of ops related to loading and saving the variables.\"\n",
    "https://www.tensorflow.org/api_docs/python/tf/graph_util/convert_variables_to_constants\n",
    "\n",
    "and then we pass that constant graph to graph_io.write_graph which writes the graph proto to a file.\n",
    "\n",
    "### Activity\n",
    "\n",
    "Click the cell below and then click **Run**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ukrida\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\ukrida\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\ukrida\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From <ipython-input-8-258782380f86>:17: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
      "WARNING:tensorflow:From C:\\Users\\ukrida\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\graph_util_impl.py:270: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "INFO:tensorflow:Froze 380 variables.\n",
      "INFO:tensorflow:Converted 380 variables to const ops.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'tf_model\\\\top_layers.iv3.pb'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.python.framework import graph_io\n",
    "\n",
    "input_model_path = top_layers_file_path\n",
    "output_model_name = \"top_layers.iv3.pb\"\n",
    "output_model_dir = \"tf_model\"\n",
    "\n",
    "K.set_learning_phase(0)\n",
    "sess = K.get_session()\n",
    "\n",
    "test_model = models.load_model(input_model_path)\n",
    "orig_output_node_names = [node.op.name for node in test_model.outputs]\n",
    "\n",
    "constant_graph = graph_util.convert_variables_to_constants(\n",
    "    sess,\n",
    "    sess.graph.as_graph_def(),\n",
    "    orig_output_node_names)\n",
    "graph_io.write_graph(\n",
    "    constant_graph,\n",
    "    output_model_dir,\n",
    "    output_model_name,\n",
    "    as_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('InceptionV3 Training and Validation Accuracy - Top Layers')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('InceptionV3 Training and Validation Loss - Top Layers')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary - Initial Training Done\n",
    "\n",
    "You've learned about the following:\n",
    "- Create DataGenerator for your dataset\n",
    "- Learn about CPU Optimization for Tensorflow\n",
    "- Understand Hyperparameter Selection\n",
    "- Compile your model\n",
    "- Learn about callbacks\n",
    "- Start your training\n",
    "- Evaluate Your Model\n",
    "- Test Your Model on a sample image\n",
    "- Freeze your graph\n",
    "\n",
    "We've now completed the first round of training!  You can now utilize the frozen graph from the end of this section to run inference with through OpenVINO.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional - Additional Training for the Entire Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tuning the Entire Network\n",
    "\n",
    "We previously fine tuned only the top layer of the network.  Now we're going to allow for all of the layers in the network to be trained but we're going to use a lower learning rate.  This will let the network narrow in and tune the remaining weights we didn't tune from the ImageNet checkpoint.\n",
    "\n",
    "We'll start by unfreezing the top two inception layers in our model and then compiling the model again.  The remaining pieces of the code will be almost identical to the above except that we're making sure to change file path names that indicate we're utilizing the top two inception nodes in this training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 149, 149, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 149, 149, 32) 96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 149, 149, 32) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 147, 147, 32) 9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 147, 147, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 147, 147, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 147, 147, 64) 18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 147, 147, 64) 192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 147, 147, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 73, 73, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 73, 73, 80)   5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 73, 73, 80)   240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 73, 73, 80)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 71, 71, 192)  138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 71, 71, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 71, 71, 192)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 35, 35, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 35, 35, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 35, 35, 48)   9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 35, 35, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 35, 35, 48)   144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 35, 35, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 35, 35, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 35, 35, 96)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 35, 35, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 35, 35, 64)   76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 35, 35, 96)   82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 35, 35, 32)   6144        average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 35, 35, 64)   192         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 35, 35, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 35, 35, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 35, 35, 32)   96          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 35, 35, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 35, 35, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 35, 35, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 35, 35, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 35, 35, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 35, 35, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 35, 35, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 35, 35, 96)   55296       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 35, 35, 48)   144         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 35, 35, 96)   288         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 35, 35, 48)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 35, 35, 96)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 35, 35, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 35, 35, 64)   76800       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 35, 35, 96)   82944       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 35, 35, 64)   16384       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 35, 35, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 35, 35, 64)   192         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 35, 35, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 35, 35, 64)   192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 35, 35, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 35, 35, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 35, 35, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 35, 35, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 35, 35, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 35, 35, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 35, 35, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 35, 35, 96)   55296       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 35, 35, 48)   144         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 35, 35, 96)   288         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 35, 35, 48)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 35, 35, 96)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 35, 35, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 35, 35, 64)   76800       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 35, 35, 96)   82944       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 35, 35, 64)   18432       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 35, 35, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 35, 35, 64)   192         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 35, 35, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 35, 35, 64)   192         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 35, 35, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 35, 35, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 35, 35, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 35, 35, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 35, 35, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 35, 35, 64)   192         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 35, 35, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 35, 35, 96)   55296       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 35, 35, 96)   288         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 35, 35, 96)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 17, 17, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 17, 17, 96)   82944       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 17, 17, 384)  1152        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 17, 17, 96)   288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 17, 17, 384)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 17, 17, 96)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 17, 17, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 17, 17, 128)  384         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 17, 17, 128)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 17, 17, 128)  114688      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 17, 17, 128)  384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 17, 17, 128)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 17, 17, 128)  114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 17, 17, 128)  384         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 17, 17, 128)  384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 17, 17, 128)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 17, 17, 128)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 17, 17, 128)  114688      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 17, 17, 128)  114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 17, 17, 128)  384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 17, 17, 128)  384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 17, 17, 128)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 17, 17, 128)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 17, 17, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 17, 17, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 17, 17, 192)  172032      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 17, 17, 192)  172032      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 17, 17, 192)  576         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 17, 17, 192)  576         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 17, 17, 192)  576         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 17, 17, 192)  576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 17, 17, 192)  0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 17, 17, 192)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 17, 17, 192)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 17, 17, 192)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_30[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 17, 17, 160)  480         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 17, 17, 160)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 17, 17, 160)  179200      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 17, 17, 160)  480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 17, 17, 160)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 17, 17, 160)  179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 17, 17, 160)  480         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 17, 17, 160)  480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 17, 17, 160)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 17, 17, 160)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 17, 17, 160)  179200      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 17, 17, 160)  179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 17, 17, 160)  480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 17, 17, 160)  480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 17, 17, 160)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 17, 17, 160)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 17, 17, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 17, 17, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 17, 17, 192)  215040      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 17, 17, 192)  215040      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 17, 17, 192)  576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 17, 17, 192)  576         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 17, 17, 192)  576         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 17, 17, 192)  576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 17, 17, 192)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 17, 17, 192)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 17, 17, 192)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 17, 17, 192)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 17, 17, 768)  0           activation_40[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 17, 17, 160)  480         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 17, 17, 160)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 17, 17, 160)  179200      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 17, 17, 160)  480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 17, 17, 160)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 17, 17, 160)  179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 17, 17, 160)  480         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 17, 17, 160)  480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 17, 17, 160)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 17, 17, 160)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 17, 17, 160)  179200      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 17, 17, 160)  179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 17, 17, 160)  480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 17, 17, 160)  480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 17, 17, 160)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 17, 17, 160)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 17, 17, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 17, 17, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 17, 17, 192)  215040      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 17, 17, 192)  215040      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 17, 17, 192)  576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 17, 17, 192)  576         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 17, 17, 192)  576         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 17, 17, 192)  576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 17, 17, 192)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 17, 17, 192)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 17, 17, 192)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 17, 17, 192)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 17, 17, 768)  0           activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "                                                                 activation_58[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 17, 17, 192)  576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 17, 17, 192)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 17, 17, 192)  258048      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 17, 17, 192)  576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 17, 17, 192)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 17, 17, 192)  258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 17, 17, 192)  576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 17, 17, 192)  576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 17, 17, 192)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 17, 17, 192)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 17, 17, 192)  258048      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 17, 17, 192)  258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 17, 17, 192)  576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 17, 17, 192)  576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 17, 17, 192)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 17, 17, 192)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 17, 17, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 17, 17, 192)  258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 17, 17, 192)  258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 17, 17, 192)  576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 17, 17, 192)  576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 17, 17, 192)  576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 17, 17, 192)  576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 17, 17, 192)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 17, 17, 192)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 17, 17, 192)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 17, 17, 192)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 17, 17, 768)  0           activation_60[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 17, 17, 192)  576         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 17, 17, 192)  0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 17, 17, 192)  258048      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 17, 17, 192)  576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 17, 17, 192)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 17, 17, 192)  258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 17, 17, 192)  576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 17, 17, 192)  576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 17, 17, 192)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 17, 17, 192)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 8, 8, 320)    552960      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 8, 8, 192)    331776      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 8, 8, 320)    960         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 8, 8, 192)    576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 8, 8, 320)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 8, 8, 192)    0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 8, 8, 1280)   0           activation_71[0][0]              \n",
      "                                                                 activation_75[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 8, 8, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 8, 8, 448)    1344        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 8, 8, 448)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 8, 8, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 8, 8, 384)    1548288     activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 8, 8, 384)    1152        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 8, 8, 384)    1152        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 8, 8, 384)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 8, 8, 384)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 8, 8, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 8, 8, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 8, 8, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 8, 8, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 8, 8, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 8, 8, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 8, 8, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 8, 8, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 8, 8, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 8, 8, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 8, 8, 192)    245760      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 8, 8, 320)    960         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 8, 8, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 8, 8, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 8, 8, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 8, 8, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 8, 8, 192)    576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 8, 8, 320)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 8, 8, 768)    0           activation_78[0][0]              \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 8, 8, 768)    0           activation_82[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 8, 8, 192)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 8, 8, 2048)   0           activation_76[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 8, 8, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 8, 8, 448)    1344        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 8, 8, 448)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 8, 8, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 8, 8, 384)    1548288     activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 8, 8, 384)    1152        conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 8, 8, 384)    1152        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 8, 8, 384)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 8, 8, 384)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 8, 8, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 8, 8, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 8, 8, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 8, 8, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 8, 8, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 8, 8, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 8, 8, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 8, 8, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 8, 8, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 8, 8, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 8, 8, 192)    393216      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 8, 8, 320)    960         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 8, 8, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 8, 8, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 8, 8, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 8, 8, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 8, 8, 192)    576         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 8, 8, 320)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 8, 8, 768)    0           activation_87[0][0]              \n",
      "                                                                 activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 8, 8, 768)    0           activation_91[0][0]              \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 8, 8, 192)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 8, 8, 2048)   0           activation_85[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1024)         2098176     global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            2050        dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 23,903,010\n",
      "Trainable params: 13,215,106\n",
      "Non-trainable params: 10,687,904\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = load_model(top_layers_file_path)\n",
    "\n",
    "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "# the first 249 layers and unfreeze the rest:\n",
    "for layer in model.layers[:249]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[249:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# we need to recompile the model for these modifications to take effect\n",
    "# we use Adam with a low learning rate\n",
    "model.compile(optimizer=optimizers.Adam(lr=0.0001), metrics=['accuracy', 'binary_accuracy'], loss='binary_crossentropy')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "48/49 [============================>.] - ETA: 10s - loss: 0.0688 - acc: 0.9819 - binary_accuracy: 0.9819\n",
      "Epoch 00001: loss improved from inf to 0.07115, saving model to inception_layers.iv3.hdf5\n",
      "49/49 [==============================] - 584s 12s/step - loss: 0.0710 - acc: 0.9819 - binary_accuracy: 0.9819 - val_loss: 0.0251 - val_acc: 0.9955 - val_binary_accuracy: 0.9955\n",
      "Epoch 2/5\n",
      "48/49 [============================>.] - ETA: 10s - loss: 0.0041 - acc: 0.9984 - binary_accuracy: 0.9984\n",
      "Epoch 00002: loss improved from 0.07115 to 0.00399, saving model to inception_layers.iv3.hdf5\n",
      "49/49 [==============================] - 544s 11s/step - loss: 0.0040 - acc: 0.9984 - binary_accuracy: 0.9984 - val_loss: 0.0199 - val_acc: 0.9955 - val_binary_accuracy: 0.9955\n",
      "Epoch 3/5\n",
      "48/49 [============================>.] - ETA: 10s - loss: 0.0039 - acc: 0.9990 - binary_accuracy: 0.9990\n",
      "Epoch 00003: loss improved from 0.00399 to 0.00384, saving model to inception_layers.iv3.hdf5\n",
      "49/49 [==============================] - 546s 11s/step - loss: 0.0038 - acc: 0.9990 - binary_accuracy: 0.9990 - val_loss: 0.0180 - val_acc: 0.9955 - val_binary_accuracy: 0.9955\n",
      "Epoch 4/5\n",
      "48/49 [============================>.] - ETA: 10s - loss: 3.1528e-04 - acc: 1.0000 - binary_accuracy: 1.0000\n",
      "Epoch 00004: loss improved from 0.00384 to 0.00031, saving model to inception_layers.iv3.hdf5\n",
      "49/49 [==============================] - 550s 11s/step - loss: 3.0909e-04 - acc: 1.0000 - binary_accuracy: 1.0000 - val_loss: 0.0173 - val_acc: 0.9955 - val_binary_accuracy: 0.9955\n",
      "Epoch 5/5\n",
      "48/49 [============================>.] - ETA: 10s - loss: 9.2802e-05 - acc: 1.0000 - binary_accuracy: 1.0000\n",
      "Epoch 00005: loss improved from 0.00031 to 0.00009, saving model to inception_layers.iv3.hdf5\n",
      "49/49 [==============================] - 548s 11s/step - loss: 9.3790e-05 - acc: 1.0000 - binary_accuracy: 1.0000 - val_loss: 0.0180 - val_acc: 0.9955 - val_binary_accuracy: 0.9955\n"
     ]
    }
   ],
   "source": [
    "#Start Training top layers\n",
    "inception_layers_file_path=\"inception_layers.iv3.hdf5\"\n",
    "checkpoint = ModelCheckpoint(inception_layers_file_path, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "train_flow.reset()\n",
    "val_flow.reset()\n",
    "history = model.fit_generator(train_flow, \n",
    "                              epochs=5, \n",
    "                              verbose=1,\n",
    "                              validation_data=val_flow,\n",
    "                              validation_steps=math.ceil(val_flow.samples/val_flow.batch_size),\n",
    "                              steps_per_epoch=math.ceil(train_flow.samples/train_flow.batch_size),\n",
    "                              callbacks=[checkpoint, early, tb, csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 93s 6s/step - loss: 0.0787 - acc: 0.9666 - binary_accuracy: 0.9666\n",
      "Loss:  0.0786550098574177\n",
      "Acc:  0.9665552\n",
      "Top 5:  0.9665552\n"
     ]
    }
   ],
   "source": [
    "#Load Trained Model and Test\n",
    "model.load_weights(inception_layers_file_path)\n",
    "test_flow.reset()\n",
    "loss, acc, top_5 = model.evaluate_generator(\n",
    "    test_flow,\n",
    "    verbose = True,\n",
    "    steps=math.ceil(test_flow.samples/test_flow.batch_size))\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Acc: \", acc)\n",
    "print(\"Top 5: \", top_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Category:  without_mask\n",
      "Raw Predictions:  [[4.0537398e-05 9.9990427e-01]]\n",
      "\n",
      "Top 3 confidence: 0.9999043 4.0537398e-05\n",
      "Top 3 labels: without_mask with_mask\n"
     ]
    }
   ],
   "source": [
    "file_list = glob.glob(\"../Dataset/test/*/*\")\n",
    "img_path = random.choice(file_list)\n",
    "img_cat = os.path.split(os.path.dirname(img_path))[1]\n",
    "print(\"Image Category: \", img_cat)\n",
    "img = image.load_img(img_path, target_size=(299, 299))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "preds = model.predict(x)\n",
    "print(\"Raw Predictions: \", preds)\n",
    "\n",
    "top_x = 3\n",
    "top_args = preds[0].argsort()[-top_x:][::-1]\n",
    "preds_label = [label[p] for p in top_args]\n",
    "print(\"\\nTop \" + str(top_x) + \" confidence: \" + \" \".join(map(str, sorted(preds[0])[-top_x:][::-1])))\n",
    "print(\"Top \" + str(top_x) + \" labels: \" + \" \".join(map(str, preds_label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 380 variables.\n",
      "INFO:tensorflow:Converted 380 variables to const ops.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'tf_model\\\\inception_layers.iv3.pb'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.python.framework import graph_io\n",
    "\n",
    "input_model_path = inception_layers_file_path\n",
    "output_model_name = \"inception_layers.iv3.pb\"\n",
    "output_model_dir = \"tf_model\"\n",
    "\n",
    "K.set_learning_phase(0)\n",
    "sess = K.get_session()\n",
    "\n",
    "test_model = models.load_model(input_model_path)\n",
    "orig_output_node_names = [node.op.name for node in test_model.outputs]\n",
    "\n",
    "constant_graph = graph_util.convert_variables_to_constants(\n",
    "    sess,\n",
    "    sess.graph.as_graph_def(),\n",
    "    orig_output_node_names)\n",
    "graph_io.write_graph(\n",
    "    constant_graph,\n",
    "    output_model_dir,\n",
    "    output_model_name,\n",
    "    as_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "#plot_model(arima_model, to_file='arima_model.png', show_shapes=True, show_layer_names=True)\n",
    "plot_model(model, to_file='IV3_model.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgQAAAHwCAYAAADZ6XcEAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAABqsUlEQVR4nO3deZxWZf3/8debYRk22d0ABVcEZZERzRWXDJfANeWrJprrNzPtZ6WVa1lWtlmWmVpa5pKlX0zU3LXUFBRQEBQRBVREkE3WYT6/P86Z8Z5hlntg7vuee3g/H4/7MWe5zjmf6z733OdzrnPd5ygiMDMzs81bq0IHYGZmZoXnhMDMzMycEJiZmZkTAjMzM8MJgZmZmeGEwMzMzHBCYDkg6TuSbil0HLki6RRJ/2rqsoUk6SpJf8nBesdJ+nfG+ApJO2RTdiO29bCk0zd2edt4kqZJGlnoOLJRTLHmmxOCIidpjqTDCrj9kZLmZU6LiB9GxFmbuN7eksol7VjLvPslXZ8OPyVpoaRlkqZIGlPH+m5KD0YrJK2VtC5j/OHGxBYRd0bE4U1dtjnKdj9kKyI6RcTsJohrgwQmIo6IiNs3dd0NbDMk7Z2rbTR3kp6WtDrjf2eFpM9FxKCIeLqJt/VwxjbWpf+3leM3bex6cxFrS+GEwJqliJgPPAGcljldUnfgSKDyi//rwDYRsQVwDvAXSdvUsr7z0oNRJ+CHwD2V4xFxRMb6W+emRsWpEfuhRZMk4MvA4vRvPrfd3D6TF2T873SKiBdysZE0wav8n70T+EnGNs/LxTY3d04IWpDKJldJ10v6RNI7kjIPdt0l/VHS++n8BzLmHS1psqQlkp6XNDhj3hxJl0mani73R0mlkjoCDwPbZmTu29Y8e5M0Om2mW5KeYexWY92XSJoqaamkeySVprNvp8aBCDgZmB4RrwFExNSIKE/nBdAG6NvI922OpG9Lmgp8Kqm1pEslvS1peVrvY2u+zxnjIek8SW+ldbwxPYA0tmyJpJ9J+jjddxek5Ws9IGQTYz2fhf6SnkmXfQzoWc9bVO9+qC+OWmIOSTulwz0kjVfSuvMSsGONsr+SNDedP0nSAen0UcB3gJPSz9yUdPrTks5Kh1tJ+p6kdyV9JOkOSV3Sef3SOE6X9F76fn+3nvoDHABsA1wInCypbUac7dP99m76Gf63pPbpvP3T/6claV3G1Yw1Ha/tc/JVSW8Bb9X3fqTzSpRcqqvcD5Mk9U0/Xz+r8b6Ol3RxA/VtFGW0VCr5/783fc+XK/nfL8sou62kvytp2XtH0oWN3NYGrZKN3H5jyu4p6dV03t+UfD/9YOPepebPCUHLszcwk+QL/ifArVJywAH+DHQABgFbAr8AkDQMuA04F+gB/B4YL6ldxnpPAb5A8qW9C/C9iPgUOAJ4PyNzfz8zGEm7AHcBFwG9gAnAg5lfqMCXgFFAf2AwMC6dfj/QU9L+GWVPo8ZZqaR/SloN/Bd4GpiYxftU01jgKKBrmmC8TXIQ6AJcTR0tDxmOBvZK4/8SyXvV2LJnk7yfQ4E9gWMaiLmhGOv7LPwVmJTO+z5Q37X3hvZDY9+rSjcCq0kOtGemr0wvk7wX3dN4/yapNCIeoXorz5Ba1j0ufR0M7AB0An5To8z+wK7AocAVykhUa3E68CBwbzr+xYx51wPDgX3TWL8FVEjaniRh/jXJZ38oMLmebdR0DMk+HJiO1/p+pPO+QfIZPhLYguS9XEmyj8ZKagUgqSdwWLp8Lo0G7ga6AuNJ3/s0jgeBKUBvkvf+Ikn1/b802fYbGWtbks/+n0je87uAOpPdFiEi/CriFzAHOCwdHgfMypjXgeSseWuSL90KoFst6/gd8P0a02YCB2Vs47yMeUcCb6fDI4F5NZa9CvhLOnw5cG/GvFbAfGBkxrpPzZj/E+CmjPFbgJvT4Z2BtcCWtdShDcnB9BtZvGdV8WXEcGYDy0wGxmS8z//OmBfA/hnj9wKXbkTZJ4FzM+YdlpZvneVnoWaMdX0WtgPKgY4Z8/+a+Z7Usu6s9kOW79VOQAmwDhiQMe+HmWVrWe8nwJDa9mE67WngrHT4CeB/M+btmm6vNdAvjaNPxvyXgJPr2G4HYBlwTDr+e+D/Mj7PqyrjqrHcZcD9dayzKtZ63qdDGtjfme/HzMr3vJZybwCfT4cvACZk83mqJ+6VwJL09UrG/1Dl99BVwOMZywwEVqXDewPv1fI+/bGB7f4J+EE6PJINv3Oy2n4jYz2Q5LtKGfP/XRlHS3y5haDl+bByICJWpoOdSJrRF0fEJ7Ussz3w/9JmzSWSlqTlt80oMzdj+N0a8+qzbVq+MqaKdF29a4uZ5MumU8b47cCJ6ZnQacCjEfFRzY1ExLqIeBg4XNLoLGPLlFk/JH1Zn11CWQLsTv3N6vXVIduy29aIo1pMNWURY12fhW2BTyJp4an0LvWrcz9sxHsFyRlzazb8XGXW7xJJb6TN8EtIWiAaWm+lap+7dLg1sFXGtGz32bEkCdSEdPxO4AhJvdJ4SklaSWrqW8f0bNX8TNb3ftS3rduBU9PhU0laCjeQXnLIptPehRHRNX3tWUeZmu9tqZJLX9uTXGLM/K75DtX3S1Ooa/uNKbstMD/STCBV7/9ksXNCsPmYC3SX1LWOeddm/JN3jYgOEXFXRpnM6/LbAZWXBhp6XOb7JF8CQFXnrL4kmXc2/k3SkWsMyZdZQ53YWlPjWnSWquqRNvX+geRsqkdEdAVeB1T7ok3mA6BPxnidfSE2McYPgG5K+oBU2q6BZWrdD5sQx0KSg2zNzxXpeg8gaXr/EkmrVldgacZ6G/W547NWkQUNLFeb00mShfckfQj8jaRF6n+Aj0kue9T2mZtbx3SAT0laHiptXUuZzM9kQ+9Hfdv6CzBG0hBgN+CB2gpF8uugXHfamwu8U+O7pnNEHNmIdVR77ySVkCSYTe0DoHfGZTZoZP+kYuOEYDMRER+QXM/8raRuktpIOjCd/QfgPEl7K9FR0lGSOmes4quS+ijpXf5d4J50+gKgh9IOW7W4FzhK0qGS2gD/D1gDPJ9l3AHcAfyY5Brfg5XzJA2QdISSTl1tJJ1K0sz3TDbrrkdHki/jhel2ziA56821e4GvK/mpX1fg2/WU3egYI+Jdkn4WV0tqm/YN+GIDy9S1HzYqjohYD/wDuEpSB0kDqd6PoTPJAXwh0FrSFSTXxistAPpVXhuvxV3AxUo6T2b+sqS8jvK1klR5nftokuv3Q4EhJO/Dl9MWr9uAnyvpLFci6XNp/5s7gcMkfUlJR9Uekoamq54MHJfWfSfgKw2E0tD7cQvwfUk7p//DgyX1AIiIeST9D/4M/D0iVjXmPWhiLwHLlXTibZ++X7tL2qsR63iT5Cz+qPQ75XtAuwaW2RgvAOuBC9L9NwYYkYPtNBtOCDYvp5FcR50BfETS0Y+ImEjSoe03JNclZ/FZx75KfwX+BcwmaZr8QbrsDJIv39lpE2C1SwkRMZPkjPLXJGdTXwS+GBFrGxH3HSRnePdExJqM6SK5BvgRyRfl14GTIuKVRqx7AxExHfgZyRfCAmAP4D+bss4s/YHkPZ4KvErSRF1O8qXU1DH+D8n13MXAlSTvcUM22A+bGMcFJGfeH5JcI/5jxrxHgUdIvvzfJTkLz2yu/Vv6d5Gk2vb3bSQHwGeBd9Llv5ZlXJlOAyZHxL8i4sPKF3ADMFjS7sAlwGskB93FJMlCq4h4j6S/zf9Lp08mSSYg6dC7luQ9u50keahPQ+/Hz0kSyn+R9He4FWifMf92kn1T6+WCfEkTwcrk6h2S74RbSC5/ZLuOpcD/psvNJ2kxmFfvQhsX61rgOJJkbQnJ99g/SU5oWiRVvzxitiFJc0g6QD1e6Fg2J0p+JnhTRGzfYGGzeqStgX8Btg9/6W80Sf8l+Z/8Y4OFi5BbCMyaibQJ9ci0ebI3yZn7/YWOy4pb2qz+deAWJwONI+kgSVun/5Onk/xU+JFCx5UrOU0IJN2m5KYgr9cxX5JukDRLyY1p9syYd7qSm7e8pYz7k0saLum1dJkbKjt8KLnpzmNp+cckdctl3cxyQCS/4/+E5JLBG8AVBY3IipqSeyssIfnZ8S8LGkxx2pXknglLSC79nJD2x2qRcnrJIG2mWgHcEREbdDSSdCTJdb0jSa5n/ioi9k47rk0Eykg6LE0ChkfEJ0ruaHYhyU1oJgA3RMTDkn5C8rO66yRdStITt75OWWZmZpbKaQtBRDxL0pmmLmNIkoWIiBeBrkrucPYF4LGIqPzd/GPAqHTeFhHxYkav52My1lX5k7Tbafgub2ZmZpYqdB+C3lTvKTsvnVbf9Hm1TAfYKqMp50Oa/kYXZmZmLVZze4pWk4iIkFTrtRBJ55A8FY+OHTsOHzBgQF5jMzNrShGwbn0F5RUVrFsflK8P1lVUJH/XJ3/LKyoor6j98nDrVqJ1SSvatBKtWuX63lu2Mfp0a08rNd2+mTRp0scRscHNnAqdEMyn+p2f+qTT5pPcrzpz+tPp9D61lAdYIGmbiPggvbSwwe1tASLiZuBmgLKyspg4cWOeg2Nmllsr15bz0bI1LFi2mo+Wr0lfq1m4bA0Llq/mo2XJtKWr1m2wbLtWok+ndmy5RTu27NyOXp1L2WqLdmzZuZQtO1dOL6Vnp7a0Lil0Q7Hlm6Rab1Ve6IRgPMldoO4m6VS4ND2gPwr8MOOXAocDl0XEYiWP/tyHpFPhl0lueFO5rtOB69K//5fPipiZNSQiWL6mPD2Yr67xt/rwijUb3lSxbUkreqUH9B16dWSfHXqwZed2bLVFKb3Sg/+WnUvp3rEtJT7bt0bKaUIg6S6SM/2eSp5ffSXJPcCJiJtIfiVwJMmd8VYCZ6TzFkv6PsmdvwCuiYjKzon/S3JXs/Ykt+J9OJ1+HXCvpK+Q3MnrS7msm5lZpYhgycp11Q7qlWfxC9NpC9KD/+p1FRssX9qmVdXZ+27bbMGBu3x2Fp95Zt+1QxvUhE3HZpk26zsV+pKBmdWnoiJYvHJtVbP9wmXVD+4fLV9TddBfu37DA32ndq3TJvvkLD6zuT4ZLmXLLdrRuV1rH+gtbyRNioiymtMLfcnAzCzvytdXsOjT9ECf2Vy/fA0fLfvsQP/xijW1dsbr0r5N1cF9RP/u1Q/ylQf6zu3o2M5fsVY8/Gk1sxZjbXkFC1ckB/UFy9awMOMs/rMz+zUs+nQNtTWOdu/YtuqAvstWnauuz2ee2ffq3I7SNiX5r5xZjjkhMLNmb/W69Z91wFue0fM+nbYwnfbJyg173LcS9OjUjq22aMfWXUoZ3KdL0oy/RSlbZZzN9+zUjrat3ePeNl9OCMysYD5dU179Z3XLajTbp8PLVm/Y4751KyU97ju3o2/3DgzfvlvSbJ/2tq88s+/RqZ173JtlwQmBmW2Syp/SLV25jmWr17F01TqWrUr+Vr6WrSqvNr501To+WraaT9eu32B9bVu3qroWv1OvTuy3Yw+23KK06uBf2fO+W4e2vpGOWRNyQmBmrK8Ilq367IBe18E880CfefCv4yZ4QNJkv0X7NnTJePXp1p6Ru/b67Pp8xpl9l/b+aZ1ZITghMGsh1pZXbHBAX1bL2XptB/nltdwEJ1ObEtGlfZuqA3uPTm3p37NjtYN85fwt2reuNq2Tf1JnVhScEJg1I6vXra9+8F5Z91l7zQP9qnUbNr9nKm3TqtqBepsupQzYunO1s/eaZ/KVr9I2rXxQN2vhnBCYNaGI4NO162s9mC9bVftw8ipn2ep1rC3f8OY2mTq1S86+O5cmf7fv0WGDM/Saw5Vn7O1a+6dyZlY3JwRmNVRUBMtXl1e7Tl6zGb628WWrk7P2up4qByBB53at6dLhswP31l1KkwN36YZn6NUO8KWt/SAaM8sZJwTWoq1cW86bC1Y0eF296sC/MrmeXt8dvUtaqfoBu0Nb+nbvUGtTe80z9s7tWrtnvJk1S04IrMVaU76e0b/5D7M+WrHBvLatq19P79Up+Ylb9c5xtV9P79C2xNfTzazFcUJgLdYtz73DrI9WcPXoQQzadotqZ+y+9ayZWXVOCKxF+mDpKn7z5CwOH7gVp+/br9DhmJk1e+6hZC3SDyfMoCKCy48eWOhQzMyKghMCa3FeeHsRD055n/MO2pG+3TsUOhwzs6LghMBalPL1FVz94DR6d23P+SN3LHQ4ZmZFI6cJgaRRkmZKmiXp0lrmby/pCUlTJT0tqU/GvB9Lej19nZQx/TlJk9PX+5IeSKePlLQ0Y94VuaybNU9/efFdZny4nMuPHuiOg2ZmjZCzToWSSoAbgc8D84CXJY2PiOkZxa4H7oiI2yUdAvwIOE3SUcCewFCgHfC0pIcjYllEHJCxjb8D/5exvuci4uhc1cmat49XrOFnj73JATv35AuDtip0OGZmRSWXLQQjgFkRMTsi1gJ3A2NqlBkIPJkOP5UxfyDwbESUR8SnwFRgVOaCkrYADgEeyE34Vmx++shMVq1dz5VfHOT7BJiZNVIuE4LewNyM8XnptExTgOPS4WOBzpJ6pNNHSeogqSdwMNC3xrLHAE9ExLKMaZ+TNEXSw5IGNVE9rAhMnruEeybO5cz9+7PTlp0KHY6ZWdEpdKfCS4CDJL0KHATMB9ZHxL+ACcDzwF3AC0DNR7mNTedVegXYPiKGAL+mjpYDSedImihp4sKFC5uyLlYgFRXBlf/3Or06t+Nrh+xU6HDMzIpSLhOC+VQ/q++TTqsSEe9HxHERMQz4bjptSfr32ogYGhGfBwS8Wblc2mowAngoY13LImJFOjwBaJOWqyYibo6Isogo69WrV9PU1ArqvknzmDJvKZcdMYDOpW0KHY6ZWVHKZULwMrCzpP6S2gInA+MzC0jqKakyhsuA29LpJemlAyQNBgYD/8pY9ATgnxGxOmNdWyu9cCxpBEndFuWkZtZsLF21jh8/MoOy7btx7LCaV6TMzCxbOfuVQUSUS7oAeBQoAW6LiGmSrgEmRsR4YCTwI0kBPAt8NV28DfBcenxfBpwaEeUZqz8ZuK7GJk8AzpdUDqwCTo6o75l11hL84rE3WbxyLbePHuGOhGZmm0Cb8zGzrKwsJk6cWOgwbCPN+HAZR93wb07eqy/XHrtHocMxMysKkiZFRFnN6YXuVGi2USKCK/9vGp1LW3PJ4bsWOhwzs6LnhMCK0j+nfsB/31nMJYfvSreObQsdjplZ0XNCYEXn0zXl/HDCGwzadgvGjtiu0OGYmbUIOetUaJYrNz41iw+WrubXY4dR0sodCc3MmoJbCKyozPn4U2557h2OG9absn7dCx2OmVmL4YTAiso1/5xO29atuPSIAYUOxcysRXFCYEXjiTcW8OSMj/j6oTuz5RalhQ7HzKxFcUJgRWH1uvVc88/p7NirI6fv26/Q4ZiZtTjuVGhF4dZ/v8O7i1by56+MoG1r57FmZk3N36zW7L2/ZBW/eXIWowZtzQE7+4FUZma54ITAmr1rJ7xBRQTfPWq3QodiZtZiOSGwZu35WR/z0NQP+N+RO9G3e4dCh2Nm1mI5IbBma936Cq56cBp9urXn3IN2KHQ4ZmYtmhMCa7b+/MK7vLlgBZcfPZDSNiWFDsfMrEVzQmDN0sLla/jFY29y4C69OHzgVoUOx8ysxfPPDpvKw5fCh68VOooWY9nCFdwSaxhc3hX9ya0DZraZ2noPOOK6vGzKLQTW7Cxfs46FK9awdZdS2vtSgZlZXuS0hUDSKOBXQAlwS0RcV2P+9sBtQC9gMXBqRMxL5/0YOCot+v2IuCed/ifgIGBpOm9cREyWpHRbRwIr0+mv5LB61eUpg2vpKiqCU377Hz5st5onLxgJ7dyIZWaWDzlrIZBUAtwIHAEMBMZKGlij2PXAHRExGLgG+FG67FHAnsBQYG/gEklbZCz3zYgYmr4mp9OOAHZOX+cAv8tFvSy37p04l6nzlvKdI3ejk5MBM7O8yeUlgxHArIiYHRFrgbuBMTXKDASeTIefypg/EHg2Isoj4lNgKjCqge2NIUkuIiJeBLpK2qYpKmL5sXTlOn7y6Ez26teNMUO3LXQ4ZmablVwmBL2BuRnj89JpmaYAx6XDxwKdJfVIp4+S1EFST+BgoG/GctdKmirpF5LaNWJ71oz9/LGZLFm5lqtH705yBcjMzPKl0J0KLwEOkvQqSb+A+cD6iPgXMAF4HrgLeAFYny5zGTAA2AvoDny7MRuUdI6kiZImLly4sGlqYZvsjQ+W8ecX3+WUvbdn4LZbNLyAmZk1qVwmBPOpflbfJ51WJSLej4jjImIY8N102pL077VpH4HPAwLeTKd/kF4WWAP8keTSRFbbS5e/OSLKIqKsVy8/KKc5iAiuHD+NLu3b8P8O36XQ4ZiZbZZymRC8DOwsqb+ktsDJwPjMApJ6SqqM4TKSXxwgqSS9dICkwcBg4F/p+DbpXwHHAK+ny48HvqzEPsDSiPggh/WzJjJ+yvu89M5ivvmFAXTt0LbQ4ZiZbZZy1o07IsolXQA8SvKzw9siYpqka4CJETEeGAn8SFIAzwJfTRdvAzyXXkdeRvJzxPJ03p2SepG0GkwGzkunTyD5yeEskp8dnpGrulnT+XRNOT+c8Aa7996Ck/bq2/ACZmaWEzn9XVdETCA5UGdOuyJj+D7gvlqWW03yS4Pa1nlIHdODzxIKKxK/eWoWC5at4benDKeklTsSmpkVSqE7FdpmbPbCFdzy3GyO37MPw7fvVuhwzMw2a04IrCAigqsfnE671iV8+4hdCx2OmdlmzwmBFcTjb3zEM28u5KLDdmbLzqWFDsfMbLPnhMDybvW69Xz/n9PZectOnL5vv0KHY2Zm+PHHVgB/eHY27y1eyZ1n7U2bEuekZmbNgb+NLa/mfbKSG5+exZF7bM1+O/UsdDhmZpZyQmB59cMJbwDw3aNq/VWpmZkViBMCy5v/zPqYCa99yFdH7kTvru0LHY6ZmWVwQmB5sW59BVeOn8Z23Ttw9oE7FDocMzOrwQmB5cXtz89h1kcruPzogZS2KSl0OGZmVoMTAsu5j5av5lePv8XIXXtx2G5bFjocMzOrhRMCy7kfPzyT1eXrueLogaQPrDIzs2bGCYHl1KR3P+Hvr8zjK/vvwA69OhU6HDMzq4MTAsuZ9RXBVeOnsdUW7fjaITsVOhwzM6uHEwLLmXtenstr85fynSN3o2M73xTTzKw5c0JgObFk5Vp++ugMRvTvzugh2xY6HDMza4ATAsuJnz/2JktXrePq0YPckdDMrAjkNCGQNErSTEmzJF1ay/ztJT0haaqkpyX1yZj3Y0mvp6+TMqbfma7zdUm3SWqTTh8paamkyenrilzWzeo2/f1l/OXFdzltn+3ZbZstCh2OmZllIWcJgaQS4EbgCGAgMFZSzRvYXw/cERGDgWuAH6XLHgXsCQwF9gYukVR5ZLkTGADsAbQHzspY33MRMTR9XZOTilm9IoIrx79O1w5t+cbndy10OGZmlqVcthCMAGZFxOyIWAvcDYypUWYg8GQ6/FTG/IHAsxFRHhGfAlOBUQARMSFSwEtAH6zZ+L/J7/PynE/41hd2pUuHNoUOx8zMspTLhKA3MDdjfF46LdMU4Lh0+Figs6Qe6fRRkjpI6gkcDPTNXDC9VHAa8EjG5M9JmiLpYUmDmq4qlo0Va8r54YQ3GNynC18q69vwAmZm1mw0mBBI+qKkXCUOlwAHSXoVOAiYD6yPiH8BE4DngbuAF4D1NZb9LUkrwnPp+CvA9hExBPg18EBtG5R0jqSJkiYuXLiwqeuzWfv1k2/x0fI1XD16EK1auSOhmVkxyeZAfxLwlqSfSBrQiHXPp/pZfZ90WpWIeD8ijouIYcB302lL0r/Xpn0BPg8IeLNyOUlXAr2Ab2Ssa1lErEiHJwBt0taFaiLi5ogoi4iyXr16NaI6Vp+3F67gtn+/w4nD+zBsu26FDsfMzBqpwYQgIk4FhgFvA3+S9EJ6lt25gUVfBnaW1F9SW+BkYHxmAUk9M1ofLgNuS6eXpJcOkDQYGAz8Kx0/C/gCMDYiKjLWtbXS37dJGpHWbVFD9bNNFxFc/eB0SluX8K1RjckZzcysucjqUkBELAPuI+kYuA3J9f5XJH2tnmXKgQuAR4E3gHsjYpqkaySNTouNBGZKehPYCrg2nd4GeE7SdOBm4NR0fQA3pWVfqPHzwhOA1yVNAW4ATk47HlqOPTZ9Ac++uZCLP78LvTq3K3Q4Zma2EdTQMTM9eJ8B7ATcAdweER9J6gBMj4h+OY8yR8rKymLixImFDqOorV63nsN+/gwd2pbw0IUH0KbE97oyM2vOJE2KiLKa07O5wfzxwC8i4tnMiRGxUtJXmipAK06/f2Y28z5ZxV/P3tvJgJlZEcsmIbgK+KByRFJ7YKuImBMRT+QqMGv+5i5eyW+fnsVRg7dh3x036L9pZmZFJJtTur8BFRnj69Nptpm79qE3aCXx3SN3K3QoZma2ibJJCFqndxoEIB1um7uQrBj8+62PeWTah1xwyE5s27V9ocMxM7NNlE1CsDDjVwFIGgN8nLuQrLlbW17BleNfZ/seHTjrgP6FDsfMzJpANn0IzgPulPQbkhsEzQW+nNOorFm7/fk5vL3wU249vYx2rUsKHY6ZmTWBBhOCiHgb2EdSp3R8Rc6jsmbro2Wr+dUTb3HIgC05dLetCh2OmZk1kWxaCCofRzwIKE1vBogfL7x5uu6RGawtr+CKo2s+ydrMzIpZNg83uonkeQZfI7lkcCKwfY7jsmZo0ruL+ccr8znrgP7069mx0OGYmVkTyqZT4b4R8WXgk4i4GvgcsEtuw7LmZn1FcMX/TWObLqVccMhOhQ7HzMyaWDYJwer070pJ2wLrSJ5nYJuRu156j2nvL+M7R+5Gh7ZZXWkyM7Miks03+4OSugI/BV4BAvhDLoOy5uWTT9dy/b9mss8O3Tl6sHNBM7OWqN6EIH008RMRsQT4u6R/AqURsTQfwVnz8LPHZrJ8dTlXjR5EZadSMzNrWeq9ZBARFcCNGeNrnAxsXl6fv5Q7//sep+2zPQO23qLQ4ZiZWY5k04fgCUnHy6eGm52I4Krx0+jeoS0Xf979SM3MWrJsEoJzSR5mtEbSMknLJS3LcVzWDDwweT4T3/2Eb48aQJf2bQodjpmZ5VA2dyrsnI9ArHlZvnodP5wwgyF9u3LC8D6FDsfMzHIsmxsTHVjbK5uVSxolaaakWZIurWX+9pKekDRV0tOS+mTM+7Gk19PXSRnT+0v6b7rOeyS1Tae3S8dnpfP7ZfUOWK1+/eQsPl6xhmtGD6JVK18tMjNr6bK5ZPDNjNflwIPAVQ0tJKmEpEPiEcBAYKykmve7vR64IyIGA9cAP0qXPQrYExgK7A1cIqmyR9uPgV9ExE7AJ8BX0ulfIbl50k7AL9JythFmfbSC2/79Dl8a3pchfbsWOhwzM8uDBhOCiPhixuvzwO4kB+KGjABmRcTsiFgL3A2MqVFmIPBkOvxUxvyBwLMRUR4RnwJTgVFpx8ZDgPvScrcDx6TDY9Jx0vmHuiNk40UEVz84jfZtS/jmqF0LHY6ZmeVJNi0ENc0DdsuiXG+SRyVnLte7RpkpwHHp8LFAZ0k90umjJHWQ1BM4GOgL9ACWRER5Leus2l46f2la3hrh0WkLeO6tj/l/n9+Fnp3aFTocMzPLkwY7FUr6NcndCSFJIIaS3LGwKVwC/EbSOOBZYD6wPiL+JWkv4HlgIfACsL4pNijpHOAcgO22264pVtlirF63nu//czoDtu7Mqfv4+VVmZpuTbG5dPDFjuBy4KyL+k8Vy80nO6iv1SadViYj3SVsIJHUCjk/vikhEXAtcm877K/AmsAjoKql12gqQuc7K7c2T1BrokpavJiJuBm4GKCsri5rzN2e/e/pt5i9Zxd3n7EPrko1pPDIzs2KVTUJwH7A6ItZD0llQUoeIWNnAci8DO0vqT3KwPhn4n8wC6eWAxekdES8DbqvcBtA1IhZJGgwMBv4VESHpKeAEkj4JpwP/l65ufDr+Qjr/yYjwAT9Lcxev5KZn3uaLQ7Zlnx18pcXMbHOT1Z0KgfYZ4+2BxxtaKD2DvwB4FHgDuDcipkm6RtLotNhIYKakN4GtSFsEgDbAc5Kmk5zNn5rRb+DbwDckzSLpI3BrOv1WoEc6/RvABj9ztLr94KHptJL4zpEDCh2KmZkVQDYtBKURsaJyJCJWSOqQzcojYgIwoca0KzKG7+OzXwxklllN8kuD2tY5m+QXDLUtc2I2cVl1z765kEenLeCbX9iVbbq0b3gBMzNrcbJpIfhU0p6VI5KGA6tyF5Ll09ryCq56cBr9enTgrAP6FzocMzMrkGxaCC4C/ibpfUDA1sBJ9S5hReOP/3mH2Qs/5Y/j9qJd65JCh2NmZgWSzbMMXpY0AKi8S83MiFiX27AsHxYsW80NT7zFYbttycEDtix0OGZmVkDZPMvgq0DHiHg9Il4HOkn639yHZrl23cMzWFcRXH50rd01zMxsM5JNH4KzK+8NABARnwBn5ywiy4uX5yzm/lfnc84BO7B9j46FDsfMzAosm4SgJPOZAOk9AtrmLiTLtfUVwZX/N41tu5TyvwfvWOhwzMysGcimU+EjwD2Sfp+Onws8nLuQLNf++tJ7TP9gGTf+z550aJvNR8DMzFq6bI4G3ya59/956fhUkl8aWBFa/Olarn90Jp/boQdH7uHdaGZmiWwef1wB/BeYQ3JDoENI7jxoRej6f81kxZpyrh4zCD8d2szMKtXZQiBpF2Bs+voYuAcgIg7OT2jW1F6fv5S7XnqPM/btzy5bdS50OGZm1ozUd8lgBvAccHREzAKQdHFeorImV1ERXPF/r9OjY1su+vzOhQ7HzMyamfouGRwHfAA8JekPkg4luVOhFaH7X53PK+8t4dujBrBFaZtCh2NmZs1MnQlBRDwQEScDA4CnSG5hvKWk30k6PE/xWRNYvnodP3p4BsO268rxe/YpdDhmZtYMZdOp8NOI+GtEfBHoA7xK8ssDKxK/evwtFn26hqtHD6JVKzfymJnZhrK5MVGViPgkIm6OiENzFZA1rVkfLedPz8/h5L36MrhP10KHY2ZmzVSjEgIrLhHBVeOn06FtCZccvmvDC5iZ2WbLCUEL9sjrH/LvWR9zyRd2pUendoUOx8zMmjEnBC3UqrXr+cFDbzBg6878z4jtCh2OmZk1czlNCCSNkjRT0ixJl9Yyf3tJT0iaKulpSX0y5v1E0jRJb0i6QYnOkiZnvD6W9Mu0/DhJCzPmnZXLujV3v3t6FvOXrOLq0YNoXeK8z8zM6pezJ9ukT0W8Efg8MA94WdL4iJieUex64I6IuF3SIcCPgNMk7QvsBwxOy/0bOCgingaGZmxjEvCPjPXdExEX5KhKReO9RSu56dnZjBm6LXvv0KPQ4ZiZWRHI5anjCGBWRMyOiLXA3cCYGmUGAk+mw09lzA+glOQxy+2ANsCCzAXTWytvSXI3Rcvw/Yem07qVuOyI3QodipmZFYlcJgS9gbkZ4/PSaZmmkNwREeBYoLOkHhHxAkmC8EH6ejQiaj5Q6WSSFoHImHZ8evnhPkl9awtK0jmSJkqauHDhwo2rWTP29MyPeGz6Ar52yM5s3aW00OGYmVmRKPTF5UuAgyS9ChwEzAfWS9oJ2I3kRki9gUMkHVBj2ZOBuzLGHwT6RcRg4DHg9to2mN5HoSwiynr16tW0tSmwteUVXPPgdHbo2ZEz9+9X6HDMzKyI5DIhmA9knqX3SadViYj3I+K4iBgGfDedtoSkteDFiFgRESuAh4HPVS4naQjQOiImZaxrUUSsSUdvAYY3fZWat9v+8w6zP/6UK744kHatSwodjpmZFZFcJgQvAztL6i+pLckZ/fjMApJ6SqqM4TLgtnT4PZKWg9aS2pC0HmReMhhL9dYBJG2TMTq6RvkW78Olq7nhibc4bLetGLnrloUOx8zMikzOfmUQEeWSLgAeBUqA2yJimqRrgIkRMR4YCfxIUgDPAl9NF78POAR4jaSD4SMR8WDG6r8EHFljkxdKGg2UA4uBcTmpWDP1o4ffoLwiuOLogYUOxczMipCq98nbvJSVlcXEiRMLHcYm++/sRZx084tceMhOfMO3KDYzs3pImhQRZTWnF7pToW2i8vUVXDl+Gr27tuf8kTsVOhwzMytSTgiK3F9feo8ZHy7ne0ftRvu27khoZmYbxwlBEVu0Yg3XPzqT/Xbqwajdty50OGZmVsScEBSx6/81k5Vr13PVFwchqdDhmJlZEXNCUKSmzlvC3S/PZdy+/dh5q86FDsfMzIqcE4IiVFERXDl+Gj06tuPrh+1c6HDMzKwFcEJQhP7+yjxefW8Jlx0xgM6lbQodjpmZtQBOCIrMstXr+PEjM9hzu64cO6zms6LMzMw2Ts7uVGi58cvH3mLRp2v50xkjaNXKHQnNzKxpuIWgiLy5YDm3vzCHsSO2Y/feXQodjpmZtSBOCIpERHDV+Gl0ateab/r2xGZm1sScEBSJCa99yPNvL+KSw3ehW8e2hQ7HzMxaGCcERWDl2nKufWg6A7fZgv/Ze/tCh2NmZi2QE4Ii8Lun3+b9pau5eswgStyR0MzMcsAJQTP37qJP+f0zszl2WG/26te90OGYmVkL5YSgmfv+P6fTpkRcdsSAQodiZmYtmBOCZuypGR/x+BsfceGhO7PlFqWFDsfMzFqwnCYEkkZJmilplqRLa5m/vaQnJE2V9LSkPhnzfiJpmqQ3JN2g9HF+abmZkianry3T6e0k3ZNu67+S+uWybrm2pnw9Vz84jR16deSM/foXOhwzM2vhcpYQSCoBbgSOAAYCYyUNrFHseuCOiBgMXAP8KF12X2A/YDCwO7AXcFDGcqdExND09VE67SvAJxGxE/AL4Me5qVl+3Prvd5izaCVXfXEQbVu7IcfMzHIrl0eaEcCsiJgdEWuBu4ExNcoMBJ5Mh5/KmB9AKdAWaAe0ARY0sL0xwO3p8H3AoZWtCsXmg6Wr+M2Tszh84FYcuEuvQodjZmabgVwmBL2BuRnj89JpmaYAx6XDxwKdJfWIiBdIEoQP0tejEfFGxnJ/TC8XXJ5x0K/aXkSUA0uBHjWDknSOpImSJi5cuHDTapgjP5wwg/UVweVH12xQMTMzy41Ct0VfAhwk6VWSSwLzgfWSdgJ2A/qQHOgPkXRAuswpEbEHcED6Oq0xG4yImyOiLCLKevVqfmffL85exINT3ue8g3akb/cOhQ7HzMw2E7lMCOYDfTPG+6TTqkTE+xFxXEQMA76bTltC0lrwYkSsiIgVwMPA59L589O/y4G/klyaqLY9Sa2BLsCinNQsR8rXV3DV+Gn07tqe80fuWOhwzMxsM5LLhOBlYGdJ/SW1BU4GxmcWkNRTUmUMlwG3pcPvkbQctJbUhqT14I10vGe6bBvgaOD1dJnxwOnp8AnAkxEROapbTvzlxXeZ8eFyLj96IKVtSgodjpmZbUZa52rFEVEu6QLgUaAEuC0ipkm6BpgYEeOBkcCPJAXwLPDVdPH7gEOA10g6GD4SEQ9K6gg8miYDJcDjwB/SZW4F/ixpFrCYJAEpGh+vWMPPH3uTA3buyRcGbVXocMysiKxbt4558+axevXqQodizUhpaSl9+vShTZs2WZVXkZ1EN6mysrKYOHFiocMA4Nv3TeXvr8zjkYsOZKctOxU6HDMrIu+88w6dO3emR48eFOmPq6yJRQSLFi1i+fLl9O9f/V42kiZFRFnNZQrdqdCAKXOXcO+kuZy5f38nA2bWaKtXr3YyYNVIokePHo1qNXJCUGAVFcEV46fRs1M7vnbIToUOx8yKlJMBq6mxnwknBAV236R5TJm7hO8cOYDOpdld5zEza04WLVrE0KFDGTp0KFtvvTW9e/euGl+7dm29y06cOJELL7ywwW3su+++TRUuABdddBG9e/emoqKiSddbzHLWqdAatnTVOn78yAzKtu/GMUNr3rPJzKw49OjRg8mTJwNw1VVX0alTJy655JKq+eXl5bRuXfvhpqysjLKyDS5nb+D5559vklgBKioquP/+++nbty/PPPMMBx98cJOtO1N99W6O3EJQQL98/E0Wr1zLVaMHubnPzFqUcePGcd5557H33nvzrW99i5deeonPfe5zDBs2jH333ZeZM2cC8PTTT3P00UcDSTJx5plnMnLkSHbYYQduuOGGqvV16tSpqvzIkSM54YQTGDBgAKeccgqVneMnTJjAgAEDGD58OBdeeGHVemt6+umnGTRoEOeffz533XVX1fQFCxZw7LHHMmTIEIYMGVKVhNxxxx0MHjyYIUOGcNppp1XV77777qs1vgMOOIDRo0czcGByt9ljjjmG4cOHM2jQIG6++eaqZR555BH23HNPhgwZwqGHHkpFRQU777wzlXfRraioYKeddiJfd9UtntSlhZn54XLueOFdTtl7O3bv3aXQ4ZhZC3H1g9OY/v6yJl3nwG234MovDmr0cvPmzeP555+npKSEZcuW8dxzz9G6dWsef/xxvvOd7/D3v/99g2VmzJjBU089xfLly9l11105//zzN/jZ3Kuvvsq0adPYdttt2W+//fjPf/5DWVkZ5557Ls8++yz9+/dn7NixdcZ11113MXbsWMaMGcN3vvMd1q1bR5s2bbjwwgs56KCDuP/++1m/fj0rVqxg2rRp/OAHP+D555+nZ8+eLF68uMF6v/LKK7z++utVvftvu+02unfvzqpVq9hrr704/vjjqaio4Oyzz66Kd/HixbRq1YpTTz2VO++8k4suuojHH3+cIUOGkK+76rqFoAAigivHv07n0tb8v8/vWuhwzMxy4sQTT6SkJLnJ2tKlSznxxBPZfffdufjii5k2bVqtyxx11FG0a9eOnj17suWWW7JgwYbPtRsxYgR9+vShVatWDB06lDlz5jBjxgx22GGHqoNwXQnB2rVrmTBhAscccwxbbLEFe++9N48++igATz75JOeffz4AJSUldOnShSeffJITTzyRnj17AtC9e/cG6z1ixIhqP/W74YYbGDJkCPvssw9z587lrbfe4sUXX+TAAw+sKle53jPPPJM77rgDSBKJM844o8HtNRW3EBTAQ699wIuzF/ODY3anW8e2hQ7HzFqQjTmTz5WOHTtWDV9++eUcfPDB3H///cyZM4eRI0fWuky7du2qhktKSigvL9+oMnV59NFHWbJkCXvssQcAK1eupH379nVeXqhL69atqzokVlRUVOs8mVnvp59+mscff5wXXniBDh06MHLkyHp/Cti3b1+22mornnzySV566SXuvPPORsW1KdxCkGcr15Zz7UNvMGjbLRg7YrtCh2NmlhdLly6ld++k8/Sf/vSnJl//rrvuyuzZs5kzZw4A99xzT63l7rrrLm655RbmzJnDnDlzeOedd3jsscdYuXIlhx56KL/73e8AWL9+PUuXLuWQQw7hb3/7G4sWJY/Gqbxk0K9fPyZNmgTA+PHjWbduXa3bW7p0Kd26daNDhw7MmDGDF198EYB99tmHZ599lnfeeafaegHOOussTj311GotLPnghCDPbnxqFh8sXc01YwZR0sodCc1s8/Ctb32Lyy67jGHDhjXqjD5b7du357e//S2jRo1i+PDhdO7cmS5dqvfPWrlyJY888ghHHXVU1bSOHTuy//778+CDD/KrX/2Kp556ij322IPhw4czffp0Bg0axHe/+10OOugghgwZwje+8Q0Azj77bJ555hmGDBnCCy+8UK1VINOoUaMoLy9nt91249JLL2WfffYBoFevXtx8880cd9xxDBkyhJNOOqlqmdGjR7NixYq8Xi4A37o4r7cunvPxpxz+i2c5evA2/PykoXnbrpm1bG+88Qa77bZbocMouBUrVtCpUycigq9+9avsvPPOXHzxxYUOq9EmTpzIxRdfzHPPPbfJ66rts+FbFzcD1/xzOm1bt+LSIwYUOhQzsxbnD3/4A0OHDmXQoEEsXbqUc889t9AhNdp1113H8ccfz49+9KO8b9stBHlqIXjijQV85faJfPfI3Tj7wB3ysk0z2zy4hcDq4haCZmb1uvVc88/p7NirI6fv26/Q4ZiZmW3APzvMg1v//Q7vLlrJn78ygratnYOZmVnz46NTjr2/ZBW/eXIWowZtzQE75+duU2ZmZo3lhCDHrp3wBhURfO9oX98zM7PmK6cJgaRRkmZKmiXp0lrmby/pCUlTJT0tqU/GvJ9ImibpDUk3KNFB0kOSZqTzrssoP07SQkmT09dZuaxbNp5/+2MemvoB/ztyJ/p061DocMzMcuLggw+uuv1vpV/+8pdVtwGuzciRI6ns1H3kkUeyZMmSDcpcddVVXH/99fVu+4EHHmD69OlV41dccQWPP/54I6Kv3+b0mOScJQSSSoAbgSOAgcBYSQNrFLseuCMiBgPXAD9Kl90X2A8YDOwO7AUcVLlMRAwAhgH7SToiY333RMTQ9HVLjqqWlXXrK7h6/HT6dGvPuQf5VwVm1nKNHTuWu+++u9q0u+++u94HDGWaMGECXbt23aht10wIrrnmGg477LCNWldNNR+TnCu5uFHTxshlC8EIYFZEzI6ItcDdwJgaZQYCT6bDT2XMD6AUaAu0A9oACyJiZUQ8BZCu8xWgD83Qn194l5kLlnPF0QMpbZO/W0+ameXbCSecwEMPPVR1P/85c+bw/vvvc8ABB3D++edTVlbGoEGDuPLKK2tdvl+/fnz88ccAXHvtteyyyy7sv//+VY9IhuQeA3vttRdDhgzh+OOPZ+XKlTz//POMHz+eb37zmwwdOpS333672mOJn3jiCYYNG8Yee+zBmWeeyZo1a6q2d+WVV7Lnnnuyxx57MGPGjFrj2twek5zLXxn0BuZmjM8D9q5RZgpwHPAr4Figs6QeEfGCpKeADwABv4mINzIXlNQV+GK6bKXjJR0IvAlcHBGZ269c7hzgHIDttsvNswQ+XrGGXzz+Jgfu0ovPD9wqJ9swM6vVw5fCh6817Tq33gOOuK7O2d27d2fEiBE8/PDDjBkzhrvvvpsvfelLSOLaa6+le/furF+/nkMPPZSpU6cyePDgWtczadIk7r77biZPnkx5eTl77rknw4cPB+C4447j7LPPBuB73/set956K1/72tcYPXo0Rx99NCeccEK1da1evZpx48bxxBNPsMsuu/DlL3+Z3/3ud1x00UUA9OzZk1deeYXf/va3XH/99dxyy4aNypvbY5IL3anwEuAgSa+SXBKYD6yXtBOwG8nZf2/gEEkHVC4kqTVwF3BDRMxOJz8I9EsvPzwG3F7bBiPi5ogoi4iyXD1j+iePzGD1uvVc+cWBSH5egZm1fJmXDTIvF9x7773sueeeDBs2jGnTplVr3q/pueee49hjj6VDhw5sscUWjB49umre66+/zgEHHMAee+zBnXfeWefjkyvNnDmT/v37s8suuwBw+umn8+yzz1bNP+644wAYPnx41QORMm2Oj0nOZQvBfKBvxnifdFqViHifpIUASZ2A4yNiiaSzgRcjYkU672Hgc0DljZ1vBt6KiF9mrGtRxqpvAX7SpLXJ0qvvfcK9E+dx7kE7sGOvToUIwcw2Z/WcyefSmDFjuPjii3nllVdYuXIlw4cP55133uH666/n5Zdfplu3bowbN67eR//WZ9y4cTzwwAMMGTKEP/3pTzz99NObFG/lI5Trenzy5viY5Fy2ELwM7Cypv6S2wMnA+MwCknpKqozhMuC2dPg9kpaD1pLakLQevJEu8wOgC3BRjXVtkzE6urJ8PlVUBFeNn8aWndvxtUN2zvfmzcwKplOnThx88MGceeaZVa0Dy5Yto2PHjnTp0oUFCxbw8MMP17uOAw88kAceeIBVq1axfPlyHnzwwap5y5cvZ5tttmHdunXVDn6dO3dm+fLlG6xr1113Zc6cOcyaNQuAP//5zxx00EEblKvL5viY5JwlBBFRDlwAPEpycL43IqZJukZSZTvQSGCmpDeBrYBr0+n3AW8Dr5H0M5gSEQ+mP0v8LklnxFdq/LzwwvSniFOAC4FxuapbXf42aS5T5i3lO0fuRqd2vgmkmW1exo4dy5QpU6oSgiFDhjBs2DAGDBjA//zP/7DffvvVu/yee+7JSSedxJAhQzjiiCPYa6+9quZ9//vfZ++992a//fZjwIDPHhB38skn89Of/pRhw4bx9ttvV00vLS3lj3/8IyeeeCJ77LEHrVq14rzzzsuqHpvrY5L9cKMmerjR0pXrOPhnT7Njr47ce+7n3HfAzPLGDzfaPGXzmOTGPNzIp7FN5LX5S1lXXsHVo3d3MmBmZjl13XXX8bvf/a5J+g5UcgtBEz7+eMWacl8qMLO8cwuB1cWPPy4QJwNmZlasnBCYmbUAm3Nrr9WusZ8JJwRmZkWutLSURYsWOSmwKhHBokWLKC0tzXoZt3GbmRW5Pn36MG/evE2+l721LKWlpfTpk/3jfpwQmJkVuTZt2lS7Ba7ZxvAlAzMzM3NCYGZmZk4IzMzMjM38xkSSFgLvNuEqewIfN+H6Csl1aZ5aSl1aSj3AdWmuWkpdclGP7SOiV82Jm3VC0NQkTazt7k/FyHVpnlpKXVpKPcB1aa5aSl3yWQ9fMjAzMzMnBGZmZuaEoKndXOgAmpDr0jy1lLq0lHqA69JctZS65K0e7kNgZmZmbiEwMzMzJwQbRdIoSTMlzZJ0aS3z20m6J53/X0n9ChBmVrKoyzhJCyVNTl9nFSLOhki6TdJHkl6vY74k3ZDWc6qkPfMdY7ayqMtISUsz9skV+Y4xG5L6SnpK0nRJ0yR9vZYyRbFfsqxLseyXUkkvSZqS1uXqWso0+++wLOtRFN9flSSVSHpV0j9rmZf7fRIRfjXiBZQAbwM7AG2BKcDAGmX+F7gpHT4ZuKfQcW9CXcYBvyl0rFnU5UBgT+D1OuYfCTwMCNgH+G+hY96EuowE/lnoOLOoxzbAnulwZ+DNWj5fRbFfsqxLsewXAZ3S4TbAf4F9apRp9t9hWdajKL6/MuL9BvDX2j5H+dgnbiFovBHArIiYHRFrgbuBMTXKjAFuT4fvAw6VpDzGmK1s6lIUIuJZYHE9RcYAd0TiRaCrpG3yE13jZFGXohARH0TEK+nwcuANoHeNYkWxX7KsS1FI3+sV6Wib9FWzM1mz/w7Lsh5FQ1If4CjgljqK5HyfOCFovN7A3IzxeWz4xVBVJiLKgaVAj7xE1zjZ1AXg+LQ59z5JffMTWpPLtq7F4nNpU+nDkgYVOpiGpM2bw0jO4jIV3X6ppy5QJPslbZqeDHwEPBYRde6X5vwdlkU9oHi+v34JfAuoqGN+zveJEwJryINAv4gYDDzGZxmqFc4rJLceHQL8GnigsOHUT1In4O/ARRGxrNDxbIoG6lI0+yUi1kfEUKAPMELS7gUOaaNkUY+i+P6SdDTwUURMKmQcTggabz6QmWX2SafVWkZSa6ALsCgv0TVOg3WJiEURsSYdvQUYnqfYmlo2+60oRMSyyqbSiJgAtJHUs8Bh1UpSG5ID6J0R8Y9aihTNfmmoLsW0XypFxBLgKWBUjVnF8h0G1F2PIvr+2g8YLWkOyaXbQyT9pUaZnO8TJwSN9zKws6T+ktqSdO4YX6PMeOD0dPgE4MlIe4I0Mw3Wpcb13NEk106L0Xjgy2mv9n2ApRHxQaGD2hiStq68dihpBMn/cbP7sk5jvBV4IyJ+Xkexotgv2dSliPZLL0ld0+H2wOeBGTWKNfvvsGzqUSzfXxFxWUT0iYh+JN/DT0bEqTWK5XyftG7KlW0OIqJc0gXAoyS99G+LiGmSrgEmRsR4ki+OP0uaRdI57OTCRVy3LOtyoaTRQDlJXcYVLOB6SLqLpJd3T0nzgCtJOhkRETcBE0h6tM8CVgJnFCbShmVRlxOA8yWVA6uAk5vbl3VqP+A04LX0Oi/Ad4DtoOj2SzZ1KZb9sg1wu6QSkqTl3oj4ZxF+h2VTj6L4/qpLvveJ71RoZmZmvmRgZmZmTgjMzMwMJwRmZmaGEwIzMzPDCYGZmZnhhMDMzMxwQmBmZmY4IbBmRNJ3JNX1pK+iJ+kUSf9q6rKFJOmqWm6x2hTrHSfp3xnjKyTtkE3ZjdjWw5JOb7hkyybpAEkzCx1HNoop1mLihGAzJWmOpMMKuP2R6V34qkTEDyPirE1cb29J5ZJ2rGXe/ZKuT4efkrRQ0rL06XS1PvZZ0k3pwWiFpLWS1mWMP9yY2CLizog4vKnLNkfZ7odsRUSniJjdBHFtkMBExBER0eQPvZH0J0k/aOr1bipJ/SRFxud4haQpEfFcROzaxNvarsZ2QtKnGeMHbMx6cxGrOSGwFiYi5gNPkNxmtoqk7iS3yK384v86sE1EbAGcA/ylxn3PK9d3Xnow6gT8ELincjwijshYv28DnqER+8EKp2vGZ3lILjYQEe9lbKNTOnlIxrTncrFd2zhOCKyqyVXS9ZI+kfSOpMyDXXdJf5T0fjr/gYx5R0uaLGmJpOclDc6YN0fSZZKmp8v9UVKppI7Aw8C2GWcK29Y8e5M0WtK0dN1PS9qtxrovUfKc86WS7pFUms6+nRoHIpL7fk+PiNcAImJq+kxxgCB5VkCjnpWexvBtSVOBTyW1lnSppLclLU/rfWzN9zljPCSdJ+mttI43SlUPx2lM2RJJP5P0cbrvLkjL15qkZBNjPZ+F/pKeSZd9DKjvaX717of64qgl5pC0UzrcQ9J4Ja07LwE71ij7K0lz0/mTKs9CJY0ief7ASZVnxen0pyWdlQ63kvQ9Se9K+kjSHZK6pPMqz6xPl/Re+n5/t57610nS2ZJmSVqc1mXbdLok/SLd9jJJryl9pK+kI9P3abmk+ZIu2Zht1xNTtVa7Bv7H6v3fz3J71VpQGrP9jYj1W5I+UPIddlbm58k+44TAKu0NzCT5gv8JcGvlAQf4M9ABGARsCfwCQNIw4DbgXKAH8HtgvKR2Ges9BfgCyZf2LsD3IuJT4Ajg/Ywzhfczg5G0C3AXcBHQi+QhOA8qeSpjpS+RPO60PzCYzx5ccj/Jg4H2zyh7GjXOSiX9U9Jq4L/A08DELN6nmsYCR5GcbZUDbwMHkDya9GrqaHnIcDSwVxr/l0jeq8aWPZvk/RwK7Akc00DMDcVY32fhr8CkdN73+ezpa7VpaD809r2qdCOwmuThNmemr0wvk7wX3dN4/yapNCIeoXorT21nxePS18HADkAn4Dc1yuwP7AocClyhjEQ1G5IOAX5Esg+3Ad4leeQtwOHAgST/K13SMpVPTLwVODciOgO7A082Zrsbqdb/sSz/93O2/UbGOgr4BnAYsBPJg8OsFk4IrNK7EfGHiFhP8oW9DbBV+gV9BHBeRHwSEesi4pl0mXOA30fEfyNifXoddg2wT8Z6fxMRcyNiMXAtyQE0GycBD0XEYxGxDrgeaA/sm1Hmhoh4P133gyQHASJiFfA34MsAknYmeQ76XzM3EBFHA51JmrD/FREVWcaW6Ya0fqvSdf4tjakiIu4B3gJG1LP8dRGxJCLeI3me+9CNKPsl4FcRMS8iPgGuqy/gLGKs67OwHUlCcnlErImIZ0ne97q2U+9+2Ij3CiVPtjseuCIiPo2I16mR6EXEXyJiUUSUR8TPgHYkB/BsnAL8PCJmR8QK4DLgZFVvbbk6IlZFxBRgCtDY5vZTSJ4s+kpErEm38TlJ/YB1JJ/JASQPn3sjPnsc9DpgoKQt0v/FVxq53Zo+Ts/ul9TT2lDr/xjZ/e83hbq235iyXwL+GBHTImIlcFUTx9hiOCGwSh9WDqT/NJCcHfUFFqcHmpq2B/5fxpfKkrT8thll5mYMv1tjXn22TctXxlSRrqt3bTGTPDq3U8b47cCJabPhacCjEfFRzY2kCc7DwOFKHpPaWJn1Q9KXM5pRl5CcydXXrF5fHbItu22NOKrFVFMWMdb1WdgW+CRt4an0LvWrcz9sxHsFSWtRazb8XGXW7xJJb6RNx0tIzrQbWm+lap+7dLg1sFXGtMbsswa3kSYei4DeEfEkSYvEjcBHkm6WtEVa9HiS5PVdJZdtPlfbypVcZsum017PiOiavurq5FlXXbP5328Kef//2Jw5IbCGzAW6S+pax7xrM75UukZEh4i4K6NM5nX57YDKSwMNPXf7fZIvHSC5tpqua36Wcf+b5JnhY4BTabgTW2tqXIvOUlU9JG0P/AG4AOgREV2B1wHVvmiT+QDokzFeZ1+ITYzxA6Cbkj4glbZrYJla98MmxLGQ5Nn2NT9XpOs9APgWyVlht3S9SzPW26jPXbrucmBBA8s1Rs3PdkeSZvf5ABFxQ0QMBwaSXDr4Zjr95YgYQ3LZ7gHg3tpWHhGD8tBpL5v//YZ8SnIpstLWTRtilaz/PzZ3TgisXmlz5cPAbyV1k9RG0oHp7D8A50naW4mOko6S1DljFV+V1EdJ7/LvAvek0xcAPZR22KrFvcBRkg6V1Ab4fyRNks9nGXcAdwA/BrqS0bQtaYCkIyS1T+tzKsl122dqXVn2OpIccBam2zmD5Kw31+4Fvq7kp35dgW/XU3ajY4yId0n6WVwtqW3aN+CLDSxT137YqDjSyxj/AK6S1EHSQKr3Y+hMcgBfCLSWdAWwRcb8BUA/SXV9990FXKyk82TmL0vK6yjfkBIlHWkrX23TbZwhaWh6zf2HwH8jYo6kvdL/pzYkB8zVQEX6fp8iqUt6CW0ZsDGXuJpKNv/7DZkMHKmk0/LWJP2FcuFekvd7N0kdgMtztJ2i54TAsnEayfXLGcBHpP+4ETGRpEPbb4BPgFls2Onnr8C/gNkknch+kC47g+SLcXba5FitqTEiZpKcUf4a+JjkwPPFiFjbiLjvIDnDuye9VltJJNcRPyI5cHwdOGlTr8lGxHTgZ8ALJAeePYD/bMo6s/QHkvd4KvAqSQfMcmB9DmL8H5JOh4uBK0ne44ZssB82MY4LSJqDPwT+BPwxY96jwCPAmyTN8qup3kT8t/TvIkm17e/bSDrRPgu8ky7/tSzjqs2lwKqM15MR8TjJQenvJGevO5L8+gKS5OUPJP9P75JcSvhpOu80YI6kZcB5JH0RCiLL//2G/JmkD8Ycks/vPfWW3kjpJcEbSPrdzAJeTGetqXOhzZSSBN6s6UmaA5yVfgFanij5meBNEbF9g4XNNjNKfhXyOtBuE1p+WiS3EJgVufTSx5FK7oPQm+TM/f5Cx2XWXEg6VlI7Sd1ILl896GRgQ0WREEi6TcmNOl6vY74k3aDkRh9TJe2Z7xjNCkgkv+P/hOSSwRvAFQWNyKx5OZfkEuHbJJfSzi9sOM1TUVwySDuxrQDuiIgNOh5JOpLkOt+RJNc3fxURe+c3SjMzs+JVFC0E6Q1QFtdTZAxJshAR8SLQVdnd8czMzMwokoQgC72p3pN4HtVvYGNmZmb12Oye0CbpHJLbbtKxY8fhAwYMKHBEZmZm+TNp0qSPI6JXzektJSGYT/W7T/WhjjvaRcTNwM0AZWVlMXHixjzPxszMrDhJqvWW4y3lksF44Mvprw32AZZmPBDEzMzMGlAULQSS7iJ5ZGVPJc/AvpLk+fVExE0kd2Y7kuQuVCuBMwoTqZmZWXEqioQgIup9ZG56v/Sv5ikcMzOzFqcoEgIzMyucdevWMW/ePFavXl3oUKwRSktL6dOnD23atMmqvBMCMzOr17x58+jcuTP9+vUjeRK5NXcRwaJFi5g3bx79+/fPapmW0qnQzMxyZPXq1fTo0cPJQBGRRI8ePRrVquOEwMzMGuRkoPg0dp85ITAzs2Zt0aJFDB06lKFDh7L11lvTu3fvqvG1a9fWu+zEiRO58MILG9zGvvvu2ySxPv300xx99NFNsq58cx8CMzNr1nr06MHkyZMBuOqqq+jUqROXXHJJ1fzy8nJat679cFZWVkZZWVmD23j++eebJNZi5hYCMzMrOuPGjeO8885j77335lvf+hYvvfQSn/vc5xg2bBj77rsvM2fOBKqfsV911VWceeaZjBw5kh122IEbbrihan2dOnWqKj9y5EhOOOEEBgwYwCmnnELlU4EnTJjAgAEDGD58OBdeeGGjWgLuuusu9thjD3bffXe+/e1vA7B+/XrGjRvH7rvvzh577MEvfvELAG644QYGDhzI4MGDOfnkkzf9zcqSWwjMzKwozZs3j+eff56SkhKWLVvGc889R+vWrXn88cf5zne+w9///vcNlpkxYwZPPfUUy5cvZ9ddd+X888/f4Gd5r776KtOmTWPbbbdlv/324z//+Q9lZWWce+65PPvss/Tv35+xY+u9PU4177//Pt/+9reZNGkS3bp14/DDD+eBBx6gb9++zJ8/n9dffx2AJUuWAHDdddfxzjvv0K5du6pp+eCEwMzMsnb1g9OY/v6yJl3nwG234MovDmr0cieeeCIlJSUALF26lNNPP5233noLSaxbt67WZY466ijatWtHu3bt2HLLLVmwYAF9+vSpVmbEiBFV04YOHcqcOXPo1KkTO+ywQ9VP+MaOHcvNN9+cVZwvv/wyI0eOpFev5HlCp5xyCs8++yyXX345s2fP5mtf+xpHHXUUhx9+OACDBw/mlFNO4ZhjjuGYY45p9PuysXzJwMzMilLHjh2rhi+//HIOPvhgXn/9dR588ME6f27Xrl27quGSkhLKy8s3qkxT6NatG1OmTGHkyJHcdNNNnHXWWQA89NBDfPWrX+WVV15hr732ytn2a3ILgZmZZW1jzuTzYenSpfTu3RuAP/3pT02+/l133ZXZs2czZ84c+vXrxz333JP1siNGjODCCy/k448/plu3btx111187Wtf4+OPP6Zt27Ycf/zx7Lrrrpx66qlUVFQwd+5cDj74YPbff3/uvvtuVqxYQdeuXZu8TjU5ITAzs6L3rW99i9NPP50f/OAHHHXUUU2+/vbt2/Pb3/6WUaNG0bFjR/baa686yz7xxBPVLkP87W9/47rrruPggw8mIjjqqKMYM2YMU6ZM4YwzzqCiogKAH/3oR6xfv55TTz2VpUuXEhFceOGFeUkGAFTZe3JzVFZWFhMnTix0GGZmzdobb7zBbrvtVugwCm7FihV06tSJiOCrX/0qO++8MxdffHGhw6pXbftO0qSI2OC3mO5DYGZmloU//OEPDB06lEGDBrF06VLOPffcQofUpHzJwMzMLAsXX3xxs28R2BRuITAzMzMnBGZmZuaEwMzMzHBCYGZmZjghMDOzZu7ggw/m0UcfrTbtl7/8Jeeff36dy4wcOZLKn5UfeeSRtT4T4KqrruL666+vd9sPPPAA06dPrxq/4oorePzxxxsRfe2a42OSnRCYmVmzNnbsWO6+++5q0+6+++6sHzA0YcKEjb65T82E4JprruGwww7bqHU1d04IzMysWTvhhBN46KGHWLt2LQBz5szh/fff54ADDuD888+nrKyMQYMGceWVV9a6fL9+/fj4448BuPbaa9lll13Yf//9qx6RDMk9Bvbaay+GDBnC8ccfz8qVK3n++ecZP3483/zmNxk6dChvv/0248aN47777gOSOxIOGzaMPfbYgzPPPJM1a9ZUbe/KK69kzz33ZI899mDGjBlZ17WQj0l2QmBmZs1a9+7dGTFiBA8//DCQtA586UtfQhLXXnstEydOZOrUqTzzzDNMnTq1zvVMmjSJu+++m8mTJzNhwgRefvnlqnnHHXccL7/8MlOmTGG33Xbj1ltvZd9992X06NH89Kc/ZfLkyey4445V5VevXs24ceO45557eO211ygvL+d3v/td1fyePXvyyiuvcP755zd4WaJS5WOSn3zySSZPnszLL7/MAw88wOTJk6sek/zaa69xxhlnAMljkl999VWmTp3KTTfd1Kj3tDa+MZGZmWXv4Uvhw9eadp1b7wFHXFdvkcrLBmPGjOHuu+/m1ltvBeDee+/l5ptvpry8nA8++IDp06czePDgWtfx3HPPceyxx9KhQwcARo8eXTXv9ddf53vf+x5LlixhxYoVfOELX6g3npkzZ9K/f3922WUXAE4//XRuvPFGLrroIiBJMACGDx/OP/7xj4bfAwr/mGS3EJiZWbM3ZswYnnjiCV555RVWrlzJ8OHDeeedd7j++ut54oknmDp1KkcddVSdjz1uyLhx4/jNb37Da6+9xpVXXrnR66lU+Qjlpnh8cr4ek+wWAjMzy14DZ/K50qlTJw4++GDOPPPMqs6Ey5Yto2PHjnTp0oUFCxbw8MMPM3LkyDrXceCBBzJu3Dguu+wyysvLefDBB6ueR7B8+XK22WYb1q1bx5133ln1KOXOnTuzfPnyDda16667MmfOHGbNmsVOO+3En//8Zw466KBNqmOhH5PshMDMzIrC2LFjOfbYY6t+cTBkyBCGDRvGgAED6Nu3L/vtt1+9y++5556cdNJJDBkyhC233LLaI4y///3vs/fee9OrVy/23nvvqiTg5JNP5uyzz+aGG26o6kwIUFpayh//+EdOPPFEysvL2WuvvTjvvPMaVZ/m9phkP/7Yjz82M6uXH39cvPz4YzMzM2sUJwRmZmbmhMDMzMyKKCGQNErSTEmzJF1ay/ztJD0l6VVJUyUdWYg4zcxaos25v1mxauw+K4qEQFIJcCNwBDAQGCtpYI1i3wPujYhhwMnAb/MbpZlZy1RaWsqiRYucFBSRiGDRokWUlpZmvUyx/OxwBDArImYDSLobGANMzygTwBbpcBfg/bxGaGbWQvXp04d58+axcOHCQodijVBaWlrtZ40NKZaEoDcwN2N8HrB3jTJXAf+S9DWgI9AyH0dlZpZnbdq0oX///oUOw3KsKC4ZZGks8KeI6AMcCfxZ0gb1k3SOpImSJjrbNTMzSxRLQjAf6Jsx3iedlukrwL0AEfECUAr0rLmiiLg5IsoioqzyARJmZmabu2JJCF4GdpbUX1Jbkk6D42uUeQ84FEDSbiQJgZsAzMzMslAUCUFElAMXAI8Cb5D8mmCapGskVT6/8v8BZ0uaAtwFjAt3iTUzM8tKsXQqJCImABNqTLsiY3g6UP+TLczMzKxWRdFCYGZmZrnlhMDMzMycEJiZmZkTAjMzM8MJgZmZmeGEwMzMzHBCYGZmZjghMDMzM5wQmJmZGU4IzMzMDCcEZmZmhhMCMzMzwwmBmZmZ4YTAzMzMcEJgZmZmOCEwMzMznBCYmZkZTgjMzMwMJwRmZmaGEwIzMzPDCYGZmZmR54RA0tckdcvnNs3MzKxh+W4h2Ap4WdK9kkZJUp63b2ZmZrXIa0IQEd8DdgZuBcYBb0n6oaQd8xmHmZmZVZf3PgQREcCH6asc6AbcJ+kn+Y7FzMzMEq3zuTFJXwe+DHwM3AJ8MyLWSWoFvAV8K5/xmJmZWSKvCQHQHTguIt7NnBgRFZKOznMsZmZmlsprQhARV0raU9IYIID/RMQr6bw38hmLmZmZfSbfPzu8HLgd6AH0BP4o6Xv5jMHMzMw2lO9LBqcCQyJiNYCk64DJwA/yHIeZmZllyPevDN4HSjPG2wHzs1kwvW/BTEmzJF1aR5kvSZouaZqkvzZBvGZmZpuFfLcQLAWmSXqMpA/B54GXJN0AEBEX1raQpBLgxrT8PJKbG42PiOkZZXYGLgP2i4hPJG2Z26qYmZm1HPlOCO5PX5WeznK5EcCsiJgNIOluYAwwPaPM2cCNEfEJQER8tMnRmpmZbSby/SuD2yW1BXZJJ82MiHVZLNobmJsxPg/Yu0aZXQAk/QcoAa6KiEc2MWQzM7PNQr5vTDSS5FcGcwABfSWdHhHPNsHqW5PcFnkk0Ad4VtIeEbGkRgznAOcAbLfddk2wWTMzs+KX706FPwMOj4iDIuJA4AvAL7JYbj7QN2O8Dxt2RpwHjI+IdRHxDvAmSYJQTUTcHBFlEVHWq1evjaqEmZlZS5PvhKBNRMysHImIN4E2WSz3MrCzpP7pJYeTgfE1yjxA0jqApJ4klxBmN0HMZmZmLV6+OxVOknQL8Jd0/BRgYkMLRUS5pAuAR0n6B9wWEdMkXQNMjIjx6bzDJU0H1pM8J2FRTmphZmbWwih5+GCeNia1A74K7J9Oeg74bUSsyVsQGcrKymLixAbzETMzsxZD0qSIKKs5PW8tBOm9BKZExADg5/narpmZmTUsb30IImI9MFOSu/abmZk1M/nuQ9CN5E6FLwGfVk6MiNF5jsPMzMwy5DshuDzP2zMzM7Ms5DshODIivp05QdKPgWfyHIeZmZllyPd9CD5fy7Qj8hyDmZmZ1ZCXFgJJ5wP/C+wgaWrGrM7A8/mIwczMzOqWr0sGfwUeBn4EXJoxfXlELM5TDGZmZlaHvCQEEbEUWAqMTe9HsFW67U6SOkXEe/mIw8zMzGqX76cdXgBcBSwAKtLJAQzOZxxmZmZWXb5/ZXARsKufMWBmZta85PtXBnNJLh2YmZlZM5LvFoLZwNOSHgKqHmgUEX62gZmZWQHlOyF4L321TV9mZmbWDOQ1IYiIq2tOk5TvpMTMzMxqyEsfAkn/zhj+c43ZL+UjBjMzM6tbvjoVdswY3r3GPOUpBjMzM6tDvhKCqGO4tnEzMzPLs3xdv+8q6ViSBKSrpOPS6QK65CkGMzMzq0O+EoJngNEZw1/MmPdsnmIwMzOzOuTrWQZn5GM7ZmZmtnHyfadCMzMza4acEJiZmZkTAjMzM8tzQiDpREmd0+HvSfqHpD3zGYOZmZltKN8tBJdHxHJJ+wOHAbcCv8tzDGZmZlZDvhOC9enfo4CbI+Ih/JAjMzOzgst3QjBf0u+Bk4AJktoVIAYzMzOrId8H4y8BjwJfiIglQHfgm3mOwczMzGrI96OHtwEeiog1kkYCg4E78hyDmZmZ1ZDvFoK/A+sl7QTcDPQF/prnGMzMzKyGfCcEFRFRDhwH/DoivknSatAgSaMkzZQ0S9Kl9ZQ7XlJIKmuimM3MzFq8fCcE6ySNBb4M/DOd1qahhSSVADcCRwADgbGSBtZSrjPwdeC/TRaxmZnZZiDfCcEZwOeAayPiHUn9gT9nsdwIYFZEzI6ItcDdwJhayn0f+DGwuqkCNjMz2xzkNSGIiOnAJcBrknYH5kXEj7NYtDcwN2N8XjqtSnrHw77pvQ3MzMysEfL6K4P0lwW3A3MAAX0lnR4Rz27ielsBPwfGZVH2HOAcgO22225TNmtmZtZi5PuSwc+AwyPioIg4EPgC8IsslptP8ouESn3SaZU6A7sDT0uaA+wDjK+tY2FE3BwRZRFR1qtXr42shpmZWcuS74SgTUTMrByJiDfJolMh8DKws6T+ktoCJwPjM9azNCJ6RkS/iOgHvAiMjoiJTRu+mZlZy5TvGxNNknQL8Jd0/BSgwYN2RJRLuoDkLoclwG0RMU3SNcDEiBhf/xrMzMysPoqI/G0seXbBV4H900nPAb+NiDV5CyJDWVlZTJzoRgQzM9t8SJoUERtcUs9bC0F6L4EpETGApAOgmZmZNRN560MQEeuBmZLctd/MzKyZyXcfgm7ANEkvAZ9WToyI0XmOw8zMzDLkOyG4PM/bMzMzsyzkJSFIn264VUQ8U2P6/sAH+YjBzMzM6pavPgS/BJbVMn1pOs/MzMwKKF8JwVYR8VrNiem0fnmKwczMzOqQr4Sgaz3z2ucpBjMzM6tDvhKCiZLOrjlR0lnApDzFYGZmZnXI168MLgLul3QKnyUAZUBb4Ng8xWBmZmZ1yEtCEBELgH0lHUzyVEKAhyLiyXxs38zMzOqX1/sQRMRTwFP53KaZmZk1LN+PPzYzM7NmyAmBmZmZOSEwMzMzJwRmZmaGEwIzMzPDCYGZmZnhhMDMzMxwQmBmZmY4ITAzMzOcEJiZmRlOCMzMzAwnBGZmZoYTAjMzM8MJgZmZmeGEwMzMzHBCYGZmZjghMDMzM5wQmJmZGU4IzMzMjCJKCCSNkjRT0ixJl9Yy/xuSpkuaKukJSdsXIk4zM7NiVBQJgaQS4EbgCGAgMFbSwBrFXgXKImIwcB/wk/xGaWZmVryKIiEARgCzImJ2RKwF7gbGZBaIiKciYmU6+iLQJ88xmpmZFa1iSQh6A3Mzxuel0+ryFeDh2mZIOkfSREkTFy5c2IQhmpmZFa9iSQiyJulUoAz4aW3zI+LmiCiLiLJevXrlNzgzM7NmqnWhA8jSfKBvxnifdFo1kg4DvgscFBFr8hSbmZlZ0SuWFoKXgZ0l9ZfUFjgZGJ9ZQNIw4PfA6Ij4qAAxmpmZFa2iSAgiohy4AHgUeAO4NyKmSbpG0ui02E+BTsDfJE2WNL6O1ZmZmVkNxXLJgIiYAEyoMe2KjOHD8h6UmZlZC1EULQRmZmaWW04IzMzMzAmBmZmZOSEwMzMznBCYmZkZTgjMzMwMJwRmZmaGEwIzMzPDCYGZmZnhhMDMzMxwQmBmZmY4ITAzMzOcEJiZmRlOCMzMzAwnBGZmZoYTAjMzM8MJgZmZmeGEwMzMzHBC0GTWra9g9br1hQ7DzMxso7QudAAtxavvLeFLv3+BrbcopW/39vTt3oG+3TqwXfcO9O2e/N2ycztatVKhQzUzM9uAE4ImstUW7bj4sF14b/FK5n6ykhfeXsT9y+YT8VmZtq1b0adb+4xEoT3bde9An24d2K5HB7YobVO4CpiZ2WbNCUET2b5HR75+2M7Vpq0pX8/8T1Yx95NVvLd4JfMWr6xKGF597xOWrS6vVr5L+zZViULNFobeXdvTtrWv8JiZWW44Icihdq1L2KFXJ3bo1anW+UtXrmPuJyuZm5EovLd4FTM+WM7j0z9i7fqKqrISbLNFaZIodK/ewtC3Wwd6dW6H5MsRZma2cZwQFFCXDm3o0qELu/fussG8iopgwfLVvLdo5QYtDM+9tZAFy9ZUK1/aplVy6aF7B/p2a18jcehAp3be1WZmVjcfJZqpVq3ENl3as02X9uxdy/zV69Yz75NVzK1sWVj0WQvDy+8sZvma6pcjundsu2GikCYQ23QtpU2JL0eYmW3OnBAUqdI2Jey0ZSd22nLDyxERwZL0csR7i1cyd3HawvDJSl6bv5RHXv+Q8orPejuWtBLbdCmt1tkxM3Ho0bGtL0eYmbVwTghaIEl069iWbh3bMrhP1w3mr68IPli6irmLM1oYFid9GZ6Y8REfr6h+OaJD2xL6dqu9s2Pf7u3p0NYfIzOzYudv8s1QSSvRp1vyc8fP7dhjg/kr15ZXXY6obGGo7Pz4wtuL+HRt9Rsw9ezUtkai8FnisE2XUlr7coSZWbPnhKCpvPs83HMatCoBtQKlf1tlDmfOU/XxquFWG5atb16929i4eR0kdmlVwi5qBe1LoG8JbJfMC4kVa4OPP13Hwk/LWbiinI9WrOWjT9exYM46prxezqSA9dGKCoRaldC9U3u27NKBXl3as1WXDmzVpQNbd+nA1t060aVDO1RrbCX11Ldy3JcxzMyaihOCptKhJwwcDVEBFeshAmJ9OlyRDDc4r3L+2oyyGfM2WE+6rsZsIyoarks9BHROX/1rK1DbvZXWAB+lryalOpIFbZhIkSYPUjJc9Zca4439mxHLRq+jrtjUyHXXtY56ytdZpyaoTzbxVCtHHdPqmp5N2fqW35T1Zlm2weXrKps5uynXm0XdAMi4o1rm3dUamt6YshtM34jt5SSOjV0HdUyPeqZlOf2AS6BNKblWNAmBpFHAr4AS4JaIuK7G/HbAHcBwYBFwUkTMyVuAvXaBo3+Rt81ttIjskpUNEpL65tWWrKTjNeatXruWRctXs2j5KhatWMUny1fzyafJa8mnq1m/fj0lVNCKCloRdGnXim4dWtOjQwldS1vTtX0rurZvTdd2rejYVrQiMyGqqCPuyiQo0v+x9D3Y6L9sOL4p66ioqL3cBtup7e9G1qfaujf1PaGedTfwHlS+d1XL1JhmttmpJWnb92tOCCpJKgFuBD4PzANeljQ+IqZnFPsK8ElE7CTpZODHwEn5j7aZU+XZWSsoyf+tkkuB3umrpojg4xVrq34RUflTyv+m/Rg+mLuKjB9H0Kaksi9E+2rPjKjsy9Clg28F3eJEA8nDpp7pNWnZupanlumNOXvMZdnGtI7UNT2X66CO6fmOYyOnb9B61rwURUIAjABmRcRsAEl3A2OAzIRgDHBVOnwf8BtJiqjrP9GaG0n06tyOXp3bMXz7bhvMX1tewQdLV1X7KWVlZ8cJr33AJyvXVSvfubR1khi03/jEYGP/Z7VBE2zut7kpNvZnpRsbqtIrE60kJNEqzVNbSek0qqZXjfPZeKtWyfzKdbRKy3+2juQvNcZF5XrTaenDxlrV3FZ943w2vSoWtEH8rfTZtgRVMbeqJe7q70P1v9Xq3+qz5ch8P6ri/Gy8VXpVJnNcKLmyljmu6rE01X7PZlX+OXPzUiwJQW9gbsb4PNjgfj1VZSKiXNJSoAfwcV4itJxr27oV2/foyPY9OtY6f/nqddXuuVD5U8oVNW7SlK2NTSU3JQPd2Px107a5kctt0jYjuQJFJF1nMsfjs/H6/lZEuh7S8YqMMtQok7GMtUxZJSBZrSfPSVEWa5p4+WF5efhdsSQETUbSOcA56egKSTObcPU9aTkJiOvSPLWUurSUeoDr0ly1lLr07PLDJq/H9rVNLJaEYD7QN2O8TzqttjLzJLUGupB0LqwmIm4Gbs5FkJImRkRZLtadb65L89RS6tJS6gGuS3PVUuqSz3oUyx1jXgZ2ltRfUlvgZGB8jTLjgdPT4ROAJ91/wMzMLDtF0UKQ9gm4AHiU5GeHt0XENEnXABMjYjxwK/BnSbOAxSRJg5mZmWWhKBICgIiYAEyoMe2KjOHVwIn5jquGnFyKKBDXpXlqKXVpKfUA16W5ail1yVs95FZ1MzMzK5Y+BGZmZpZDTgg2gqRRkmZKmiXp0lrmt5N0Tzr/v5L6FSDMrGRRl3GSFkqanL7OKkScDZF0m6SPJL1ex3xJuiGt51RJe+Y7xmxlUZeRkpZm7JMraitXaJL6SnpK0nRJ0yR9vZYyRbFfsqxLseyXUkkvSZqS1uXqWso0+++wLOtRFN9flSSVSHpV0j9rmZf7fZLctMOvbF8knRrfBnYA2gJTgIE1yvwvcFM6fDJwT6Hj3oS6jAN+U+hYs6jLgcCewOt1zD8SeJjkfiL7AP8tdMybUJeRwD8LHWcW9dgG2DMd7gy8Wcvnqyj2S5Z1KZb9IqBTOtwG+C+wT40yzf47LMt6FMX3V0a83wD+WtvnKB/7xC0EjVd1G+WIWAtU3kY50xjg9nT4PuBQNc97dGZTl6IQEc+S/LqkLmOAOyLxItBV0jb5ia5xsqhLUYiIDyLilXR4OfAGGz7Goij2S5Z1KQrpe70iHW2Tvmp2Jmv232FZ1qNoSOoDHAXcUkeRnO8TJwSNV9ttlGt+MVS7jTJQeRvl5iabugAcnzbn3iepby3zi0G2dS0Wn0ubSh+WNKjQwTQkbd4cRnIWl6no9ks9dYEi2S9p0/RkkoeSPxYRde6X5vwdlkU9oHi+v34JfAuo6xn1Od8nTgisIQ8C/SJiMPAYn2WoVjivANtHxBDg18ADhQ2nfpI6AX8HLoqIZYWOZ1M0UJei2S8RsT4ihpLc9XWEpN0LHNJGyaIeRfH9Jelo4KOImFTIOJwQNF5jbqOM6rmNcjPQYF0iYlFErElHbwGG5ym2ppbNfisKEbGssqk0kvtztJHUs8Bh1UpSG5ID6J0R8Y9aihTNfmmoLsW0XypFxBLgKWBUjVnF8h0G1F2PIvr+2g8YLWkOyaXbQyT9pUaZnO8TJwSN15Juo9xgXWpczx1Ncu20GI0Hvpz2at8HWBoRHxQ6qI0haevKa4eSRpD8Hze7L+s0xluBNyLi53UUK4r9kk1dimi/9JLUNR1uD3wemFGjWLP/DsumHsXy/RURl0VEn4joR/I9/GREnFqjWM73SdHcqbC5iBZ0G+Us63KhpNFAOUldxhUs4HpIuoukl3dPSfOAK0k6GRERN5Hc5fJIYBawEjijMJE2LIu6nACcL6kcWAWc3Ny+rFP7AacBr6XXeQG+A2wHRbdfsqlLseyXbYDbJZWQJC33RsQ/i/A7LJt6FMX3V13yvU98p0IzMzPzJQMzMzNzQmBmZmY4ITAzMzOcEJiZmRlOCMzMzAwnBGbWTCl5euAGT30zs9xwQmBmZmZOCMxs00g6NX0u/WRJv08fOLNC0i/S59Q/IalXWnaopBfTh83cL6lbOn0nSY+nDwZ6RdKO6eo7pQ+lmSHpzub2xD2zlsQJgZltNEm7AScB+6UPmVkPnAJ0JLnD2iDgGZK7LQLcAXw7fdjMaxnT7wRuTB8MtC9QefviYcBFwEBgB5I7BppZDvjWxWa2KQ4leWDMy+nJe3uSR9FWAPekZf4C/ENSF6BrRDyTTr8d+JukzkDviLgfICJWA6Treyki5qXjk4F+wL9zXiuzzZATAjPbFAJuj4jLqk2ULq9RbmPvkb4mY3g9/s4yyxlfMjCzTfEEcIKkLQEkdZe0Pcl3ywlpmf8B/h0RS4FPJB2QTj8NeCYilgPzJB2TrqOdpA75rISZOds2s00QEdMlfQ/4l6RWwDrgq8CnwIh03kck/QwgeXzrTekBfzafPd3wNOD36dPd1gEn5rEaZoafdmhmOSBpRUR0KnQcZpY9XzIwMzMztxCYmZmZWwjMzMwMJwRmZmaGEwIzMzPDCYGZmZnhhMDMzMxwQmBmZmbA/wc3hJRkt0eHEAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('InceptionV3 Training and Validation Accuracy - Fine Tuning')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('InceptionV3 Training and Validation Loss - Fine Tuning')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources\n",
    "\n",
    "TensorFlow* Optimizations on Modern Intel® Architecture, https://software.intel.com/en-us/articles/tensorflow-optimizations-on-modern-intel-architecture\n",
    "\n",
    "Intel Optimized TensorFlow Wheel Now Available, https://software.intel.com/en-us/articles/intel-optimized-tensorflow-wheel-now-available\n",
    "\n",
    "Build and Install TensorFlow* on Intel® Architecture, https://software.intel.com/en-us/articles/build-and-install-tensorflow-on-intel-architecture\n",
    "\n",
    "TensorFlow, https://www.tensorflow.org/\n",
    "\n",
    "### Case Studies\n",
    "\n",
    "Manufacturing Package Fault Detection Using Deep Learning, https://software.intel.com/en-us/articles/manufacturing-package-fault-detection-using-deep-learning\n",
    "\n",
    "Automatic Defect Inspection Using Deep Learning for Solar Farm, https://software.intel.com/en-us/articles/automatic-defect-inspection-using-deep-learning-for-solar-farm\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:opencv-forge] *",
   "language": "python",
   "name": "conda-env-opencv-forge-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
